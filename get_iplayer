#!/usr/bin/perl
#
# get_iplayer
#
# Lists and downloads BBC iplayer mov streams
#
# Author: P Lewis
# Email: iplayer (at sign) linuxcentre.net
# License: GPLv3 (see LICENSE.txt)
# Date: June 15th 2008
# Version: 0.19
#
# Supports: 
# * Downloading Mov streams from BBC Iplayer site - 20080312
# * Automatic XOR decoding of files - 20080609
# * XOR decoding of previously downloaded files - 20080609
# * Indexing of all available (i.e. listed) Iplayer programs (now uses A-Z index page with search set to '*') - 20080609
# * Caching of Index (default 24hrs)
# * Creation of a basic html index file
# * De-duplication of programme index
# * HTTP Proxy support - 20080610
# * Regex search on programme name capability (makes it useful to run this from crontab)
# * Regex search on long programme description/episode capability (-l) - 20080610
# * Restarting downloads of incomplete files
# * Tested on Linux (Fedora 6/7/8/9, Centos/RHEL 5, Ubuntu)
#
# Changes 0.19 - 20080614:
# * Fixed PID searching
# * Now supports restarting downloads of incomplete files
# * Fixed swap detection bug where moov atom started on even byte offset
# * Remaining time added
# * Fixed kbps (not misreported kBps anymore)
#
# Changes 0.18 - 20080613:
# * Auto detection of byte-swapping
# * Auto detection of XOR sequence
#
# Changes 0.17 - 20080612:
# * Non-UK error detection
# * Not available error detection
#
# Changes 0.16 - 20080612:
# * Fixed HTML output links 
# * Sanitized data structures
# * Now parses days/hours left
# * Fixed XOR % completion calculation
# * Reads IPLAYER_OUTDIR environment
#
# Changes 0.15 - 20080611:
# * Fixed duplicate programme removal
# * Now supports different programme type downloads (i.e. Original, Signed, etc)
# * Changes hashes to give more meaningful names
# * Test option (-t) will now determine the programme type
# * Increased speed of XOR decoder by reading in 1024 blocks at a time
#
# Changes 0.14 - 20080611:
# * Not using curl anymore - seems to fail through some firewalls mysteriously and will not work on Ubuntu
# * Using LWP for all http requests
# * Fixed indexing sort bug
#
# Requires:
# * perl 5.8
# * perl LWP

use strict;
use URI;
use IO::Socket;
use vars qw($opt_h $opt_t $opt_d $opt_f $opt_o $opt_p $opt_e $opt_l $opt_n $opt_v $opt_w);
use Getopt::Std;
use Fcntl;
use File::stat;
use File::Copy;
use IO::Seekable;
use LWP::UserAgent;
#use LWP::Debug qw(+);
use HTTP::Cookies;
use HTTP::Headers;
my $DEBUG = 0;
$|=1;

sub usage {
	print "Usage:\n";
	print "  Download files:        get_iplayer [-l] [-t] [-f] [-n] [-w] [-v] [-e <secs>] [-o <dir>] [-p <proxy_url>] <regex|index|pid|url> [<regex|index|pid|url>]\n";
	print "  Decode Existing Files: get_iplayer [-v] -d <files to decode>\n";
	print "  List Programmes:       get_iplayer [-v] [-l] [-e <secs>] [-p <proxy_url>]\n";
	print "Options:\n";
	print "       -l        show/search long programme descriptions\n";
	print "       -d        Perform XOR decoding/byte-swapping on specified existing files\n";
	print "       -t        test only - no download (will show programme type)\n";
	print "       -f        flush cache\n";
	print "       -e <secs> cache expiry in seconds\n";
	print "       -o <dir>  Download output directory\n";
	print "       -p <url>  Web proxy URL spec (only used for parsing iplayer site - not downloads)\n";
	print "       -n        Do not perform XOR decoding/byte-swapping after downloading\n";
	print "       -w        keep whitespace (and escape chars) in filenames\n";
	print "       -v        verbose\n";
	print "       -h        help\n";
	exit 1;
}

# Parse options
usage() if (! getopts("htwnvdfo:p:e:l")) || $opt_h;

# Options
my $download_dir 	= $opt_o || "$ENV{IPLAYER_OUTDIR}" || '.';
my $webfile 		= $download_dir.'/iplayer.html';
my $cookiejar		= "/tmp/iplayer_cookie_$$";
my $cachefile		= '/tmp/iplayer.cache';
my $cache_secs 		= $opt_e || 86000;

my $url_download_prefix	= 'http://www.bbc.co.uk/mediaselector/3/auth/iplayer_streaming_http_mp4';
my $prog_page_prefix	= 'http://www.bbc.co.uk/programmes';
my $search_page_prefix	= 'http://www.bbc.co.uk/iplayer/atoz/?filter=azgroup%3A*&start=';
my %ua = (
  	coremedia	=> "Apple iPhone v1.1.1 CoreMedia v1.0.0.3A110a",
  	safari		=> "Mozilla/5.0 (iPhone; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A110a Safari/419.3",
);

# Programme data structure
# $prog{$pid} = {
#	'index'		=> <index number>,
#	'name'		=> <programme short name>,
#	'urlpid'	=> <pid from the URL>,
#	'episode'	=> <Episode info>,
#	'desc'		=> <Long Description>,
#	'available'	=> <No. of days/hours left>,
#	'longname'	=> <Long name (only parsed in stage 1)>,
#	'type'		=> <Programme type i.e. Original/Signed (only parsed in stage 1)>,
#};
my %prog;
# Hash to obtain pid given an index
my %index_pid;

# Web proxy
my $proxy_url = $opt_p || $ENV{HTTP_PROXY} || $ENV{http_proxy} || '';
print "INFO: Using Proxy $proxy_url\n" if $proxy_url;

# XOR Decode-only mode
if ($opt_d) {
	for my $file (@ARGV) {
		if ( -f $file ) {
			iplayer_decoder($file);
		} else {
			print "ERROR: Cannot find $file\n";
		}
	}
	exit 0;
}

# Check for valid dload dir
die ("ERROR: $download_dir does not exist\n") if ! -d $download_dir;

# Flush cache if required
unlink ($cachefile) if $opt_f;

# Get stream links from BBC iplayer site or from cache (also populates all hashes)
get_links();

# Print list of programmes if we're not downloading anything
if ( ! $ARGV[0] ) {
	list_progs( sort { $a <=> $b } keys %index_pid );
        exit 0;
}

# Parse remaining args
my @download_list;
for ( @ARGV ) {
        chomp();
        # If Numerical value
        if ( /^[\d]+$/ ) {
                push @download_list, $_;

        # If PID then find matching programmes with this PID
        } elsif ( /^.*b0[a-z,0-9]{6}.*$/ ) {
                s/^.*(b0[a-z,0-9]{6}).*$/$1/g;
                push @download_list, get_regex_matches( $1 );

        # Else assume this is a programme name regex
        } else {
                push @download_list, get_regex_matches( $_ );
        }
}

# Display list for download
print "Download List:\n" if @download_list;
list_progs( @download_list );

# Do the downloads based on list of index numbers
download_stream_lwp( $index_pid{$_} ) for (@download_list);

exit 0;


# Lists progs given an array of index numbers
sub list_progs {
	for (@_) {
		my $pid = $index_pid{$_};
		my $desc = "- $prog{$pid}{desc}" if $opt_l;
		print "$_: $prog{$pid}{name} - $prog{$pid}{episode} $desc ($prog{$pid}{available})\n";	
	}
	print "\n";
	return 0;
}

# Get matching programme index numbers using supplied regex
sub get_regex_matches {

	my $download_regex = shift;
	my @download_list;
	
	for (keys %index_pid) {
		my $pid = $index_pid{$_};
		# Search prognames/pids
		push @download_list, $_ if $prog{$pid}{name} =~ /$download_regex/i || $pid =~ /$download_regex/i || $prog{$pid}{urlpid} =~ /$download_regex/i;
		# Also search long descriptions and episode data if -l is specified
		push @download_list, $_ if $opt_l && ( $prog{$pid}{desc} =~ /$download_regex/i 
			|| $prog{$pid}{episode} =~ /$download_regex/i );
	}
	return sort {$a <=> $b} @download_list;
}


sub get_links_all {
	my $pageno = 1;
	my $pid;
	my @html;
	my $valid = 1;
	print "INFO: Getting Index page\n";
	# Setup User agent
	my $ua = LWP::UserAgent->new;
	$ua->timeout([10]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->agent( $ua{safari} );

	# Loop while we still get stream links
	my $index = 1;
	do {
		print "DEBUG: Getting ${search_page_prefix}${pageno}\n" if $DEBUG;

		# Get index pages
		my $res = $ua->request( HTTP::Request->new( GET => "${search_page_prefix}${pageno}" ) );
		@html = split /\n/, $res->content;
		# Set valid flag if we have progdata in this page
		$valid = 0 if ! grep(/version_pid=\w+">[^<]+<\/a>/, @html);
		if ( ! $res->is_success ) {
			print "ERROR: Failed to get programme index page ${pageno} from iplayer site\n";
			exit 2;
		} else {
			print ".";
		}

		# Get the complete URL
		# e.g.:  <a class="resultlink" href="/iplayer/page/item/b00bwky1.shtml?filter=azgroup%3A%2A&amp;start=33&amp;scope=iplayeratoz&amp;version_pid=b00c3kcd">Wild China</a>
		# Get Episode info: Info follows for upto 40 lines after matched line, e.g.
		# ........
		#		<span class="available">
		#		
		#			16 hours left
		#		
		#		</span>
		#	</p>
		# .........
		#                                       <div class="resultSynopsis">
		#                <p class="title">
		#                        <strong>Stake Out</strong>
		#                        <span class="divider">|</span>
		#                        Episode 7
		#                </p>
		#                <p class="description">Children's hidden camera game show that finds out how well kids know their mates. The Prince of Askabar visits Edinb
		#        </div>

		# parse @html array for episode info
		while (@html) {
			my $progdata;
			chomp( my $line = shift @html );
			# If this line has a version_pid line (i.e. one with anchor text in it)
			if ( $line =~ /version_pid=\w+">[^<]+<\/a>/ ) {
				# Need version_pid & url (note these are different pids)
				# Get url and extract the URLPID and PID
				$line =~ s/^.*href=\".*(b0.{6})\.shtml\?.*version_pid=(\w+)">[^<]+<\/a>/$1 $2/;
				my $urlpid = $1;
				my $pid = $2;
				# get next 40 lines into a single string
				$progdata = '';
				$progdata .= shift @html for (1..40);
				# Extract prog data
				$progdata =~ s!^.*<span class=\"available\">\s*([\w ]+)\s*</span>.*<p class=\"title\">\s*<strong>(.+)</strong>.+</span>\s*([^<]+)</p>.*<p class=\"description\">([^<]+).*$!$1|$2|$3|$4!g;
				# Remove unwanted whitespace
				$progdata =~ s/\s*$//g;
				$progdata =~ s/\s*\|/|/g;
				$progdata =~ s/\|\s*/|/g;
				print "urlpid|pid|available|prog|episode|desc = '$urlpid|$pid|$progdata'\n" if $opt_v;
				my ($urlpid, $pid, $available, $name, $episode, $desc) = split /\|/, "$urlpid|$pid|$progdata";;
				# Duplicate detection
				if ( not defined $prog{$pid}{name} ) {
					# Create data structure with prog data
					$prog{$pid} = {
						'index'		=> $index,
						'name'		=> $name,
						'urlpid'	=> $urlpid,
						'episode'	=> $episode,
						'desc'		=> $desc,
						'available'	=> $available,
					};
					$index_pid{$index}	= $pid;
					print "  $name ($pid) - $episode - $desc\n" if $opt_v;
					$index++;
				} else {
					print "WARNING: removing duplicate entry for \"$name ($pid) - $episode\"\n" if $opt_v;
				}
			}
		}
		# Next page
		$pageno++;
	} while ($valid);
	print "\n";
	return 0;
}


sub get_links {
	my @cache;
	my $now = time();

	# Open cache file (need to verify we can even read this)
	if ( open(CACHE, "< $cachefile") ) {
		@cache = <CACHE>;
		close (CACHE);
	}

	# if a cache file doesn't exist/corrupted or original file is older than 2 mins then download new data
	if ( ($cache[0] =~ /^0$/) || (! -f $cachefile) || ($now >= ( stat($cachefile)->mtime + $cache_secs )) ) {

		# Use A-Z,0-9 searchine '*' instead - less pages
		get_links_all();

		# Open cache file for writing
		if ( open(CACHE, "> $cachefile") ) {
			for (sort {$a <=> $b} keys %index_pid) {
				my $pid = $index_pid{$_};
				print CACHE "$_|$prog{$pid}{name}|$pid|$prog{$pid}{urlpid}|$prog{$pid}{available}|$prog{$pid}{episode}|$prog{$pid}{desc}\n";
			}
			close (CACHE);
			# Make sure anyone can read/write file (security risk here!!)
			chmod 0777, $cachefile;
		} else {
			print "WARNING: Couldn't open cache file for writing\n";
		}


	# Else read from cache
	} else {
		for (@cache) {
			# Populate %prog from cache
			chomp();
			my ($index, $name, $pid, $urlpid, $available, $episode, $desc) = split /\|/;
			# Create data structure with prog data
			$prog{$pid} = {
				'index'		=> $index,
				'name'		=> $name,
				'urlpid'	=> $urlpid,
				'episode'	=> $episode,
				'desc'		=> $desc,
				'available'	=> $available,
			};
			$index_pid{$index}	= $pid;
		}
	}

	# Create local web page
	if ( open(HTML, "> $webfile") ) {
	  print HTML '<html><head></head><body><table border=1>';
	  for (sort {$a <=> $b} keys %index_pid) {
            my $pid = $index_pid{$_};
	    my $urlpid = $prog{$pid}{urlpid};
	    my $name = $prog{$pid}{name};
	    print HTML "<tr>
	      <td rowspan=2 width=150><a href=\"${prog_page_prefix}/${urlpid}.html\"><img height=84 width=150 src=\"http://www.bbc.co.uk/iplayer/images/episode/${urlpid}_150_84.jpg\"></a></td>
	      <td>$_</td><td><a href=\"${prog_page_prefix}/${urlpid}.html\">${name}</a></td> <td>$prog{$pid}{episode}</td>
	    </tr>
	    <tr>
	      <td colspan=4>$prog{$pid}{desc}</td>
	    </tr>
	    \n";
	  }
	  print HTML '</table></body>';
	  close (HTML);
	} else {
	  print "Couldn't open html file $webfile for writing\n";
	}
	
	return 0;
}


# Usage: download_stream_lwp (<pid>)
sub download_stream_lwp {
	my $pid = shift;
	
	# Create a full URL from the PID specified
	my $page = "http://www.bbc.co.uk/iplayer/page/item/".$prog{$pid}{urlpid}.".shtml";
	print "INFO: Attempting to Download: $prog{$pid}{name} - $prog{$pid}{episode}\n";


	print "INFO: Stage 1 URL = $page\n" if $opt_v;
	print "\rGetting iplayer programme page        " if ! $opt_v;
	# Switch off automatic redirects
	my $ua = LWP::UserAgent->new( requests_redirectable => [] );
	# Setup user agent
	# 30 second request timeout
	$ua->timeout([30]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 1, ignore_discard => 0 ) );
		

	# Stage 1: get PID and set cookie
	$ua->agent( $ua{safari} );
	# send request
	my $res = $ua->request( HTTP::Request->new( GET => $page ) );
	if ( ! $res->is_success ) {
		print "\rERROR: Failed to get programme ID from iplayer site\n\n";
		return 7;
	}
	my @content = split /\n/, $res->content;
	# Non-UK detection
	if ( grep /only available to play in the UK/i, @content ) {
		print "\nERROR: This service will only work from the UK or via a UK based web proxy.\n";
		exit 3;
	}
	# Extract Long Name, e.g.: iplayer.prog = " The Really Wild Show: Series 21"; 
	chomp( $prog{$pid}{longname} = (grep /^\s*iplayer.prog = \".+"/, @content)[0] );
	$prog{$pid}{longname} =~ s/^\s*iplayer.prog = "\s*(.+)\s*".*$/$1/g;

	# Extract pid and type (i.e. Signed, Original, etc)
	chomp( my @type_pid = grep /(type|pid )      :/, @content );
	# Remove tags
	s/^.*'(.+)'.*$/$1/g for @type_pid;
	# Get hash of pid => type
	my %types = @type_pid;
	my %pid_types;
	$pid_types{$types{$_}}=$_ for keys %types;
	$prog{$pid}{type} = $pid_types{$pid};
	# List types available
	print "INFO: Types available: ", join(', ', %pid_types), "\n" if $opt_v;
	# Create url
	my $url_1 = "${url_download_prefix}/$pid";
	# Create a filename
	my $file = "$prog{$pid}{longname} - $prog{$pid}{episode} - $pid_types{$pid}";
	# Replace slashes with _ regardless
	$file =~ s/[\\\/]/_/g;
	# Sanitize by default
	$file =~ s/\s/_/g if ! $opt_w;
	$file =~ s/[^\w_-]//gi if ! $opt_w;

	print "INFO: Stage 2 Type = $prog{$pid}{type}\n" if $opt_v;
	print "INFO: Stage 2 URL = $url_1\n" if $opt_v;
	print "\rINFO: File name = $file.mov                 \n";

	# Skip from here if we are only testing downloads
	return 0 if $opt_t;

	my $file_done = "${download_dir}/${file}.mov";
	$file = "${file_done}.part";
	if ( -f $file_done ) {
		print "ERROR: File already exists\n\n";
		return 1;
	} else {

		# Stage 2: e.g. "Location: http://download.iplayer.bbc.co.uk/iplayer_streaming_http_mp4/121285241910131406.mp4?token=iVXexp1yQt4jalB2Hkl%2BMqI25nz2WKiSsqD7LzRmowrwXGe%2Bq94k8KPsm7pI8kDkLslodvHySUyU%0ApM76%2BxEGtoQTF20ZdFjuqo1%2B3b7Qmb2StOGniozptrHEVQl%2FYebFKVNINg%3D%3D%0A"
		print "\rGetting iplayer download URL         " if ! $opt_v;
		my $h = new HTTP::Headers(
			'User-Agent'	=> $ua{coremedia},
			'Accept'	=> '*/*',
			'Range'		=> 'bytes=0-1',
		);
		my $req = HTTP::Request->new ('GET', $url_1, $h);
		# send request
		my $res = $ua->request($req);
		# Get resulting Location header (i.e. redirect URL)
		my $url_2 = $res->header("location");
		if ( ! $res->is_redirect ) {
			print "ERROR: Failed to get redirect from iplayer site\n\n";
			return 2;
		}
		# Extract redirection Location URL
		$url_2 =~ s/^Location: (.*)$/$1/g;
		# If we get a Redirection containing statuscode=404 then this prog is not yet ready
		if ( $url_2 =~ /statuscode=404/ ) {
			print "\rERROR: Programme is not yet ready for download\n\n";
			return 3;
		}
		print "INFO: Stage 3 URL = $url_2\n" if $opt_v;


		# Stage 3: Download File
		# Open output file for appending/writing
		if ( ! open(FILE, ">> $file") ) {
			print("ERROR: Cannot write or append to $file\n\n");
			return 4;
		}
                # Determine offset for continuation dowload
		my $orig_length = stat($file)->size;
		my $h = new HTTP::Headers(
			'User-Agent'	=> $ua{coremedia},
			'Accept'	=> '*/*',
			'Range'		=> 'bytes='.$orig_length.'-',
		);
		my $req = HTTP::Request->new ('GET', $url_2, $h);
		# Set time to use for download rate calculation
		my $now = time();
		# Define callback sub that gets called during download request
		# This sub actually writes to the open output file and reports on progress
		my $callback = sub { 
			my ($data, $res, undef) = @_;
			print FILE $data;
			my $size = stat($file)->size - $orig_length;
			printf( "%8.2f MB / %.2f MB %5.0f kbps %5.1f%% %5.0f s remaining        \r", 
                                ($size + $orig_length) / 1024.0 / 1024.0, 
                                ($res->header("Content-Length") + $orig_length) / 1024.0 / 1024.0,
                                ($size * 8.0) / (stat($file)->mtime - $now + 0.01) / 1024.0,
                                100.0 * ($size + $orig_length) / ($orig_length + $res->header("Content-Length")),
                                ($res->header("Content-Length") - $size) * ( stat($file)->mtime - $now ) / ( $size + 1000 )
                        );
		};
		# send request
		print "\nINFO: Continuing download from byte $orig_length\n" if $orig_length;
		print "\r                              \r";
		my $res = $ua->request($req, $callback);
		close FILE;
                # If we don't require any more bytes (previously fully downloaded) then skip
                print "Content-Length = ".$res->header("Content-Length")."\n";
		if (! $res->is_success) {
			print "ERROR: Failed to Download file\n\n";
			# If this really was a failure from http then the dload is prob corrupted
                        unlink $file;
			unlink $cookiejar;
			return 5;
		} else {
			print "INFO: Downloaded $file_done (".$res->header("Content-Length")." bytes)\n";
			# Moving file into place as complete
                        move($file, $file_done);
		}
	}
	# XOR Decode if required
	iplayer_decoder($file_done) if ! $opt_n;

	return 0;
}



# In-place modification of an iplayer file to do that dodgy xor stuff
#
# Usage: iplayer_decode <filename>
#
# * Modifies 2MB blksize bytes at a time for speed
# * This process is NON reversible
#
sub iplayer_decoder {

  chomp( my $file = shift );
  if (! -f $file) {
	print "ERROR: File $file does not exist - no decoding performed\n";
  	return 1;
  }

  if (! open (FILE, "+<$file") ) {
  	print "ERROR: Can't update $file: $!";
  	return 1;
  }


  # Open file
  open (FILE, "+<$file") || die "ERROR: Can't write to file $file: $!";

  # Get mdat box end start
  my $mdat_start = 0x1c;
  my $mdat_end_offset_chars = get_block( $mdat_start, 4 );
  my $mdat_end_offset = bytestring_to_int($mdat_end_offset_chars);
  print "mdat_end_offset = ".get_hex($mdat_end_offset_chars)." = $mdat_end_offset\n" if $opt_v;
  print "mdat_end_offset (decimal) = $mdat_end_offset\n" if $opt_v;


  # The MOOV box starts one byte after MDAT box ends
  my $moov_start = $mdat_start + $mdat_end_offset;
  # Read start+4 + 4 bytes to get 'moov' text
  my $moov_start_chars = get_block( $moov_start + 4, 4 );
  print "BYTES: $moov_start_chars, HEX: ".get_hex($moov_start_chars)."\n" if $opt_v;

  # see if we need any decoding
  if ( $moov_start_chars !~ /moov/ ) {

    # Get xor pattern
    my $pattern = get_xor_pattern( $moov_start );
    $pattern =~ s/(\w\w)(\w\w)/$1 $2/g;
    my $byte1 = hex $1;
    my $byte2 = hex $2;

    # Create long string of byte pairs
    my $xor_test = create_pattern_string(2, $byte1, $byte2);
    # We need a different xor pattern if we have an odd offset
    if ( odd($moov_start) ) {
      $xor_test = create_pattern_string(2, $byte2, $byte1);
    } else {
      $xor_test = create_pattern_string(2, $byte1, $byte2);
    }

    # XOR this 'moov' string
    my $buffer = $moov_start_chars ^ $xor_test;
    print "INFO: Swap Test (after XOR on 'moov') BYTES: $buffer, HEX: ".get_hex($buffer)."\n" if $opt_v;

    # if we get 'moov' then no byte-swapping is required
    if ( $buffer =~ /moov/ ) {
      print "INFO: Swapping bytes not required\n";
    } else {
      print "INFO: Swapping bytes required\n";
      print "INFO: Will perform byte-swapping\n";
      process_file($file, 'swap');
    }

    # Do XORing if required
    # Get XOR pattern from this
    my $pattern = get_xor_pattern( $moov_start );
    if ( $pattern =~ /0000/ ) {
	print "INFO: No XOR required\n";
    } else {
	print "INFO: XOR with '0x$pattern' required\n";
	print "INFO: Will perform XOR using 0x${pattern}\n";
	process_file($file, 'xor', $pattern);
    }






  } else {
    print "INFO: No XOR or Byte swapping required\n";
  }




  close FILE || die "Closing: $!";
  return 0;
}


# Get XOR pattern from moov_start_offset
sub get_xor_pattern {
    my $moov_start = shift;
    my $moov_zeroes_chars;
    
    # determine XOR pattern from zeroes area
    # Get the zero byte section in the MOOV box
    my $moov_zeroes_start = $moov_start + 0x3D;
    # Add one to this number to make it even to get the correct xor sequence
    if ( odd( $moov_zeroes_start ) ) {
      $moov_zeroes_start++;
      print "DEBUG: making moov_zeroes_start offset even" if $opt_v;
    }
    # Read start+ 0x3d + 2 bytes to get '00 00'
    $moov_zeroes_chars = get_block( $moov_zeroes_start, 2 );
    print "INFO: Swap Test (moov zeroes for xor) BYTES: $moov_zeroes_chars, HEX: ".get_hex($moov_zeroes_chars)."\n" if $opt_v;

    # Extract the two hex bytes from the pattern
    my $pattern = get_hex($moov_zeroes_chars);
    $pattern =~ s/ //g;
    print "DEBUG: XOR pattern = $pattern\n" if $opt_v;
    return $pattern;
    # Use swapped pattern
}


# process_file(<file>, 'xor', <pattern>)
# process_file(<file>, 'swap)
sub process_file {
	my $file = shift;
	my $recsize = 4096 * 512;
	# Offsets
	# Start offset MUST be even
	my $start_offset = 0x2800;
	my $end_offset = 0x400 + 2;
	print "INFO: Using offsets Begin: ".$start_offset.", End: ".$end_offset."\n" if $opt_v;
	my $buffer;
	my $do_xor;
	my $do_swap;
	my $opt = shift;
	my ($ooff, $ffoo);
	my ($byte1, $byte2, $xor);

	# XOR setup
	if ($opt =~ /xor/i) {
		$do_xor = 1;
		# Extract the two hex bytes from the pattern
		my $pattern = shift;
		$pattern =~ s/(\w\w)(\w\w)/$1 $2/g;
		$byte1 = hex $1;
		$byte2 = hex $2;
		# Create long string of byte pairs
		$xor = create_pattern_string($recsize/2, $byte1, $byte2);

	# Swap setup
	} else {
		$do_swap = 1;
		# Create long string of '00FF's
		$ooff = create_pattern_string($recsize/2, 0x00, 0xff);
		# Create long string of 'FF00's
		$ffoo = create_pattern_string($recsize/2, 0xff, 0x00);
	}

	print "INFO: ($opt) Only processing $recsize bytes from $start_offset\n";

	my $length =  stat($file)->size;
	print "$file length = $length\n" if $opt_v;

	# Put file ptr in correct place
	seek(FILE, $start_offset, SEEK_SET);

	# Do the xoring
	for (my $i = $start_offset; $i < ($length - $end_offset); $i += $recsize) {

		# Make sure we don't touch last 0x402 bytes
		if ( $i > ($length - $end_offset - $recsize) ) {
			$recsize = $length - $end_offset - $i;
			$xor = create_pattern_string($recsize/2, $byte1, $byte2);
			print "\nINFO: ($opt) Only processing $recsize bytes from $i\n";
		}

		read(FILE, $buffer, $recsize) == $recsize
			|| die "\nReading: $!";

		# Do the XOR
		$buffer = $buffer ^ $xor if $do_xor;
	
		# Do the byte swapping
		if ($do_swap) {
			# AND buffer with 0xFF00 pattern
	                my $a = $buffer & $ffoo;
	                # AND buffer with 0x00FF pattern
	                my $b = $buffer & $ooff;
	                # Right-shift bufferA one byte
	                chop($a);
	                my $c = "\0".$a;
	                # Left-shift bufferB one byte
	                my $d = substr($b, 1)."\0";
	                # OR buffers together
			$buffer = $c | $d;
		}
		# Rewind $buffer bytes then rewrite xor'ed data
		seek(FILE, -1 * $recsize, SEEK_CUR);
		print FILE $buffer;

		printf "\r%0.2f%%", $i/$length*100.0 if ! $opt_v;
		printf "\r%0.2f%%, offset = %X, blksize = %d bytes, (length = %X, start = %X, end = %X)", $i/$length*100.0, $i, $recsize, $length, $start_offset, $length - $end_offset  if $opt_v;
	}

	# Last two bytes (length-0x402)->(length-0x401) have xor pattern swapped
	my $xor = create_pattern_string(1, $byte2, $byte1);
	print "\nINFO: ($opt) processing 2 bytes from ".($length - $end_offset)."\n";
	seek(FILE, $length - $end_offset, SEEK_SET);
	read(FILE, $buffer, 2) == 2 || die "Reading: $!";

	# Do the XOR using reverse
	$buffer = $buffer ^ $xor if $do_xor;

	# Rewind $buffer bytes then rewrite xor'ed data
	seek(FILE, -2, SEEK_CUR);
	print FILE $buffer;
}



# Build XOR/Mask pattern
sub create_pattern_string {
	my $count = shift;

	my $pat;
	$pat .= chr($_) for @_;
	print "Pattern = $pat\n" if $opt_v;

	my $ret;
	for (my $i = 0; $i<$count; $i++) { 
		$ret .= $pat;
	}
	return $ret; 
}

# Returns arbitrary block of data from open FILE
sub get_block {
	my $start = shift;
	my $len = shift;
	my $buf;
	# Seek to start offset
	seek(FILE, $start, SEEK_SET);
	# Read bytes
	read(FILE, $buf, $len) == $len || die "\nReading: $!";
	return $buf;
}

# Converts a string of chars to it's HEX representation
sub get_hex {
        my $buf = shift;
        my $ret;
        for (my $i=0; $i<length($buf); $i++) {
                $ret .= " ".sprintf("%02lx", ord substr($buf, $i, 1) );
        }
	print "DEBUG: HEX string value = $ret\n" if $opt_v;
        return $ret;
}

# Converts a string of chars to it's MSB decimal value
sub bytestring_to_int {
	# Reverse to LSB order
        my $buf = reverse shift;
        my $dec;
        for (my $i=0; $i<length($buf); $i++) {
		# Multiply byte value by 256^$i then accumulate
                $dec += (ord substr($buf, $i, 1)) * 256 ** $i;
        }
	print "DEBUG: Decimal value = $dec\n" if $opt_v;
        return $dec;
}

sub odd() {
    return 1 if ( ($_[0]/2.0) != int($_[0]/2.0) );
    return 0;
}