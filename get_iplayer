#!/usr/bin/perl
#
# Lists and downloads BBC iplayer mp4 streams
#
use strict;
use URI;
use IO::Socket;
use vars qw($opt_t $opt_d $opt_f $opt_o $opt_p $opt_e $opt_l $opt_n);
use Getopt::Std;
use Fcntl;
use File::stat;
use IO::Seekable;

# Parse options
if (! getopts("tnd:fo:p:e:l")) {
        print "Usage: get_iplayer [-l] [-t] [-d <days to parse from site>] [-e <cache expiry secs>] [-f] [-o <output dir>] [-p <proxy_url>] -- <regex|index|pid>\n";
        print "       -l          show long programme descriptions\n";
        print "       -t          test only - no download\n";
        print "       -f          flush cache\n";
        print "       -d <days>   number of days of programmes to populate the cache with\n";
        print "       -e <secs>   cache expiry in seconds\n";
        print "       -o <dir>    Download output directory\n";
        print "       -p <url>    Web proxy URL spec (only used for parsing iplayer site - not downloads)\n";
        print "       -n          Do not perform XOR conversion\n";
        exit 1;
}

my $download = join ',', @ARGV;
my $download_dir = $opt_o || "$ENV{HOME}/nfs/video/TV/iplayer";

# Check for valid dload dir
if (! -d $download_dir ) {
  die ("ERROR: $download_dir does not exist\n");
}

my $proxy_url = $opt_p || $ENV{HTTP_PROXY} || $ENV{http_proxy} || '';
my $days = $opt_d || 7;

my $url_download_prefix = 'http://www.bbc.co.uk/mediaselector/3/auth/iplayer_streaming_http_mp4';
my $prog_page_prefix = 'http://www.bbc.co.uk/programmes';
my %ua = (
  coremedia => "Apple iPhone v1.1.1 CoreMedia v1.0.0.3A110a",
  safari => "Mozilla/5.0 (iPhone; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A110a Safari/419.3",
);

my (%links, %daymonth, %slot, %urls, %streams, %prog_index, %pids, %episodes, %descriptions);
my $now = time();
my $cachefile = '/tmp/iplayer.cache';
my $webfile = $download_dir.'/index.html';
my $cache_secs = $opt_e || 86000;
my ( $videourl, $video_id, $cookie, $title, $full, @vers, $prev_url );

# Flush cache if required
unlink ($cachefile) if $opt_f;

# Assume the argv is a regex statement if it doesnt contain just numbers/commas
# See if a URL conaining a PID is specified e.g. b00?????
my $download_regex;
if ($download !~ /^[\d,]+$/) {
    $download_regex = $ARGV[0];
    # if we have a pid...
    if ($download =~ /^.*b00[a-z,0-9]{5}.*$/) {
      $download_regex =~ s/^.*(b00[a-z,0-9]{5}).*$/$1/g;
    }
    print "Seaching for programme names containing: '$download_regex'\n";
}

# Set web proxy env var if required
$ENV{HTTP_PROXY} = $proxy_url if $proxy_url;
$ENV{http_proxy} = $proxy_url if $proxy_url;

# Get straem links from BBC iplayer site or from cache
get_links();

# Print list of streams
my $count = 1;
for (sort keys %links) {
        my $desc = "- $descriptions{$_}" if $opt_l;
	print "$count: $_ - $episodes{$_} - $daymonth{$_} $slot{$_} $desc\n" if ! $download;
	$streams{$count} = $links{$_};
	$prog_index{$_} = $count;
	$count++;
}

# Get matching programmes
if ($download_regex) {
	$download = '';
	my @matches = sort grep /$download_regex/i, keys %links;
	print "Download Matches:\n";
	for (@matches) {
	        my $desc = "- $descriptions{$_}" if $opt_l;
		print "$prog_index{$_}: $_ - $episodes{$_} - $daymonth{$_} $slot{$_} $desc\n";
		$download .= "$prog_index{$_},";
	}
}

# Do the downloads
if ($download) {
	my @dl = split /[\s,]+/, $download;
	for (@dl) {
		chomp();
		# Reset globals between dloads
		$videourl = $video_id =	$cookie = $title = $full = $prev_url = '';
		@vers = ();
                if (! $opt_t) {
		  print "Attempting to Download '$urls{$streams{$_}}': ";
		  download_stream( $streams{$_} );
                }
	} 
}

exit 0;


sub get_links_for_date {
	my ($day, $month, $slot) = @_;
	my $pageno = 1;
	my $pid;
	my @page;
	print "Results for $day / $month / $slot:\n";
	# Loop while we still get stream links
	do {
		@page = ();
		my @html = `curl $proxy_url -A "$ua{safari}" "http://www.bbc.co.uk/iplayer/last7days/?filter=txdate%3A${day}-${month}&filter=txslot%3A${slot}&start=${pageno}&scope=iplayerlast7days" 2>/dev/null`;

		# Get the complete URL
		# e.g.:  <a class="resultlink" href="/iplayer/page/item/b009gn1m.shtml?filter=txdate%3A13-03&amp;filter=txslot%3Aafternoon&amp;start=1&amp;scope=iplayerlast7days&amp;version_pid=b009gmpz">In The Night Garden</a>
		# We just need this in the form of /iplayer/page/item/b009gn1m.shtml|<progname>
		# s/^.*href=\"(.*\.shtml)\?.*version_pid=\w+">([^<]+)<\/a>/$1|$2/g for @page;

                # Get Episode info: Info follows for upto 40 lines after matched line, e.g.
		#                                       <div class="resultSynopsis">
		#                <p class="title">
		#                        <strong>Stake Out</strong>
		#                        <span class="divider">|</span>
		#                        Episode 7
		#                </p>
		#                <p class="description">Children's hidden camera game show that finds out how well kids know their mates. The Prince of Askabar visits Edinb
		#        </div>

		# parse @html array for episode info
		for (my $i=0; $i<$#html; $i++) {
			my $block;
			# If this is a version_pid line
			if ( $html[$i] =~ /version_pid=\w+">[^<]+<\/a>/ ) {
				# Get url
				my $url = $html[$i];
				$url =~ s/^.*href=\"(.*\.shtml)\?.*version_pid=\w+">[^<]+<\/a>/$1/g;
				chomp($url);
				# get next 40 lines into a single string
				for (my $j=1; $j<=40; $j++) {
					$block .= $html[$i+$j];
					chomp($block);
				}
				$i += 40;
				my $progdata = $block;
				$progdata =~ s!^.*<p class=\"title\">\s*<strong>(.+)</strong>.+</span>\s*([^<]+)</p>.*<p class=\"description\">([^<]+).*$!$1|$2|$3!g;
                                # Remove unwanted whitespace
				$progdata =~ s/\s*$//g;
                                $progdata =~ s/\s*\|/|/g;
                                $progdata =~ s/\|\s*/|/g;
				print "url|title|episode|desc = '$url|$progdata'\n";
				push @page, "$url|$progdata";
			}
		}


		for (@page) {
			my ($url, $progname, $episode, $desc) = split /\|/;
			#$url = $url_download_prefix.$url;
			# Get the pid for duplicate detection
			$pid = $url;
			$pid =~ s/^.*\/(\w+)\.shtml/$1/g;
			# Duplicate detection
			if ( not defined $pids{$pid} ) {
				$links{"$progname ($pid)"} = $url;
				# Other hashes for categorisation
				$daymonth{"$progname ($pid)"} = $day."/".$month;
				$slot{"$progname ($pid)"} = $slot;
				# Used to detect duplicates
				$urls{$url} = "$progname ($pid)";
				$pids{$pid} = "$progname/$episode/$day/$month/$slot";
				$episodes{"$progname ($pid)"} = $episode;
				$descriptions{"$progname ($pid)"} = $desc;
                                print "  $progname - $episode - $desc\n";
				# Link Validation here...
			} else {
				#print "WARNING: removing duplicate stream link for \"$progname ($episode)\" / $pids{$pid}\n";
			}

		}
		# Next page
		$pageno++;
	} while ($#page >= 0);
	print "\n";
}


sub get_links {
	my @cache;

	# Open cache file (need to verify we can even read this)
	if ( open(CACHE, "< $cachefile") ) {
		@cache = <CACHE>;
		close (CACHE);
	}

	# if a cache file doesn't exist/corrupted or original file is older than 2 mins then download new data
	if ( ($cache[0] =~ /^0$/) || (! -f $cachefile) || ($now >= ( stat($cachefile)->mtime + $cache_secs )) ) {

		# Get last $days of listings
		for (my $i=$days; $i>=0; $i--) {
			chomp( my ($d, $m) = split /\s+/, `date +'%d %m' -d "$i days ago"` );
			for my $s qw(morning afternoon evening) {
				get_links_for_date($d,$m,$s);
			}
		}

		# Open cache file for writing
		if ( open(CACHE, "> $cachefile") ) {
			for (sort keys %links) {
				print CACHE "$_|$links{$_}|$episodes{$_}|$descriptions{$_}|$daymonth{$_}|$slot{$_}\n";
			}
			close (CACHE);
			# Make sure anyone can read/write file
			`chmod 777 $cachefile`;
		} else {
			print "Couldn't open cache file for writing\n";
		}


	# Else read from cache
	} else {
		for (@cache) {
			# Populate %links from cache
			chomp();
			my ($progname, $url, $episode, $desc, $dm, $s) = split /\|/;
                        $links{$progname} = $url;
			$daymonth{$progname} = $dm;
			$slot{$progname} = $s;
			$urls{$url} = $progname;
			$episodes{$progname} = $episode;
			$descriptions{$progname} = $desc;
		}
	}

        # Create local web page
	if ( open(HTML, "> $webfile") ) {
	  print HTML '<html><head></head><body><table border=1>';
          for (sort keys %links) {
            # Extract pid from progname
            my $pid = $_;
            $pid =~ s/^.*\((b00.....)\).*$/$1/g;
            my $title = $_;
            $title =~ s/^(.*)\s*\(.*$/$1/g;
            print HTML "<tr>
              <td rowspan=2 width=150><a href=\"${prog_page_prefix}/${pid}.html\"><img height=84 width=150 src=\"http://www.bbc.co.uk/iplayer/images/episode/${pid}_150_84.jpg\"></a></td>
              <td><a href=\"${prog_page_prefix}/${pid}.html\">${title}</a></td> <td>$episodes{$_}</td> <td>$daymonth{$_} $slot{$_}</td>
            </tr>
            <tr>
              <td colspan=4>$descriptions{$_}</td>
            </tr>
            \n";
          }
          print HTML '</table></body>';
          close (HTML);
        } else {
	  print "Couldn't open html file $webfile for writing\n";
        }
        
	return 0;
}


# Usage: download_stream (<pid>|<url>)

sub download_stream {

	my $id = shift;
	$id = $1 if $id =~ /\/(b.*?)\.shtml/;
	my $page = "http://www.bbc.co.uk/iplayer/page/item/$id.shtml";

	my $sock = iphone_req($page, "safari", "");
	
	while(<$sock>) {
	  print if $ENV{DEBUG};
	  
	  if(/Location: (.*)/) {
	    $videourl = $1;
	    $sock = iphone_req($1, "coremedia", "Range: bytes=0-1\r\n");
	  } elsif(/Set-Cookie: (BBC-UID.*?);/i) {
	    $cookie = $1;

	    my $text = join "", <$sock>; # keepalive causes a pause here

	    @vers = ($text =~ /iplayer.versions.*?Original.*?'(\w+)/s);
	    push @vers, $text =~ /iplayer.versions(?:.*?pid\s*:\s*'(\w+)')+/sg;

	    if(@vers) {
	      $video_id = shift @vers;

	      if($text =~ m!<p class="heading">([^<]+)</p>(?:.*?<h2>(.*?)</h2>)?!s) {
	        $title = "$1" . ($2 ? " - $2" : "");
	        $title =~ s/[^-A-Z0-9 ']/ /ig;
	        $title =~ s/(?:^\s+|\s+$)//g;
	        $title =~ s/\s{2,}/ /g;
	      } else {
	        $title = $video_id;
	      }

	      $sock = iphone_req("$url_download_prefix/$video_id?" . int(rand 1e6) . "%20", "coremedia", "Range: bytes=0-1\r\n");
	    } else {
	      print "ERROR: video id not found\n";
	      return 1;
	    }
	  } elsif(!$full && /^Content-Range: .*\/(\d+)\r?$/) {
	    $full = $1;
	    $sock = iphone_req($videourl, "coremedia", "Range: bytes=0-$1\r\n");
	  } elsif(/^\r?$/) {
	    if(!$full) {
	      if(@vers) { # try another version (maybe signed still available?)
	        $video_id = shift @vers;
	        $sock = iphone_req("$url_download_prefix/$video_id?" . int(rand 1e6) . "%20", "coremedia", "Range: bytes=0-1\r\n");
	      } else {
	        print  "ERROR: Didn't find anything to download!\n";
                return 2;
  	      }
	    } else {
	      save_to_file($sock, $full);
	      return 0;
	    }
	  }
	}
	return 0;
}


sub iphone_req {
  my($url, $ua, $add) = @_;
  my $type = $prev_url ? "new_abs" : "new";
  $url = URI->$type($url, $prev_url) unless ref $url;
  $prev_url = $url;

  my $path = $url->path . ($url->query ? "?" . $url->query : "");
  my $host = $url->host;

  ####print "--> $path\n";

  my $req = <<EOF;
GET $path HTTP/1.1\r
Accept: */*\r
Accept-Language: en\r
Accept-Encoding: gzip, deflate\r
Cookie: $cookie\r
User-Agent: $ua{$ua}\r
Connection: keep-alive\r
${add}Host: $host\r
\r
EOF
  my $sock = IO::Socket::INET->new("$host:80") or die $!;
  print $sock $req;
  return $sock;
}


sub save_to_file {
  my($sock, $full) = @_;

  my $file = "$download_dir/$title.mp4";
  # Remove spaces and change to underscores
  $file =~ s/\s/_/g;
  if ( -f $file ) {
  	print "ERROR: File already exists - skipping....\n";
		return 0;
  }
  printf "\nSaving to $file (%0.1fMB)\n", $full/(1<<20);

  open my $fh, ">$file" or die $!;
  binmode $fh;
  binmode $sock;
  my $buf;
  my($s,$p);

  $|++;
  my $start = time;
  while($s=read $sock, $buf, 1<<16) {
    $p+=$s;
    printf "\r%0.2f%% (%0.2f KiB/s)",
			($p/$full) * 100, $p / ((time - $start) || 1) / 1024;
    print $fh $buf or die "HMM!";
  }
  print "\n";

  # Decode if required
  iplayer_decoder($file) if ! $opt_n;

  return 0;
}


# In-place modification of an iplayer file to do that dodgy xor stuff
#
# Usage: iplayer_decode <filename>
#
sub iplayer_decoder {
  chomp( my $file = shift );
  my $length =  stat($file)->size;
  print "$file length = $length\n";

  open (FILE, "+<$file") || die "can't update $file: $!";

  my $buffer;

  # Use preferred blocksize
  my $recsize = stat($file)->blksize;

  # Create long string of '0x3c53's
  my $xor = create_xor_string($recsize/2, 0x3c, 0x53);

  # Offsets
  my $start_offset = 0x2800;
  my $end_offset = 0x400 + 2;

  # Put file ptr in correct place
  seek(FILE, $start_offset, SEEK_SET);

  print "INFO: Only XORing $recsize bytes from $start_offset\n";

  # Do the xoring
  for (my $i = $start_offset; $i < ($length - $end_offset); $i += $recsize) {

	# Make sure we don't touch last 0x402 bytes
	if ( $i > ($length - $end_offset - $recsize) ) {
		$recsize = $length - $end_offset - $i;
		$xor = create_xor_string($recsize/2, 0x3c, 0x53);
		print "\nINFO: Only XORing $recsize bytes from $i\n";
	}

	read(FILE, $buffer, $recsize) == $recsize
		|| die "\nReading: $!";

	# Do the XOR
	$buffer = $buffer ^ $xor;

	# Rewind $buffer bytes then rewrite xor'ed data
	seek(FILE, -1 * $recsize, SEEK_CUR);
	print FILE $buffer;

	printf "\r%0.2f%%", $i/$length*100.0;
	#printf "\r%0.2f%%, offset = %X, blksize = %d bytes, (length = %X, start = %X, end = %X)", $i/$length*100.0, $i, $recsize, $length, $start_offset, $length - $end_offset;
  }

  # Last two bytes (length-0x402)->(length-0x401) have xor pattern swapped
  my $xor = create_xor_string(1, 0x53, 0x3c);
  print "\nINFO: XORing 2 bytes from ".($length - $end_offset)."\n";
  seek(FILE, $length - $end_offset, SEEK_SET);
  read(FILE, $buffer, 2) == 2 || die "Reading: $!";

  # Do the XOR using 0x53,0x3c
  $buffer = $buffer ^ $xor;

  # Rewind $buffer bytes then rewrite xor'ed data
  seek(FILE, -2, SEEK_CUR);
  print FILE $buffer;

  close FILE || die "Closing: $!";
}

# Build XOR pattern
sub create_xor_string {
	my $count = shift;

	my $pattern;
	$pattern .= chr($_) for @_;

	my $ret;
	for (my $i = 0; $i<$count; $i++) { 
		$ret .= $pattern;
	}
	return $ret; 
}

exit 0;
