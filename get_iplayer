#!/usr/bin/perl
#
# get_iplayer
#
# Lists and downloads BBC iPlayer audio and video streams
#
# Author: Phil Lewis
# Email: iplayer (at sign) linuxcentre.net
# Web: http://linuxcentre.net
# License: GPLv3 (see LICENSE.txt)
# Date: September 26th 2008
#
my $version = 0.77;
#
# Supports: 
# * Downloading h.264/Mov/Quicktime Video and mp3/realaudio Radio streams and podcasts from BBC iPlayer site
# * Downloads streams from BBC iPlayer site (--get)
# * Re-jigs the mov file so that video can be streamed and start faster on some players
# * Resume downloads of partially downloaded files
# * Indexing of all available Podcast, Radio and TV (i.e. listed) iPlayer programs using Atom and RSS feeds
# * Info option (--info) to get full programme metadata
# * Caching of Programme Index (default 4hrs)
# * Lists programmes added since last cache refresh (--since)
# * Creation of a basic html index file (--html <file>)
# * Execution of a custom user command after every successful download (--command)
# * HTTP Proxy support (maybe broken for now on some proxies) (--proxy)
# * Regex search on programme name capability (makes it useful to run this from crontab)
# * Regex search on long programme description/episode capability (--long)
# * Regex search on channel and category (--channel, --category, --exclude-channel, --exclude-category)
# * Search by type 'tv', 'radio', 'podcast', or 'all' (default: --type=tv)
# * Save default options in ~/.get_iplayer/config (--save)
# * Tested on Linux (Fedora 6/7/8/9, Centos/RHEL 5, *Ubuntu, Xebian, Unslung/NSLU2)
# * Tested on MacOSX, and Windows ActivePerl (no realaudio radio to stdout), cygwin
#
# Requires:
# * perl 5.8
# * LWP (libwww-perl)
# * mplayer, lame and tee (for realaudio radio transcoded mp3 stdout support only)
#
# Todo:
# ** Use non-shell tee?
# ** Fix non-uk detection - iphone auth?
# ** Index/Download live radio streams w/schedule feeds to assist timing
# ** Podcasts for 'local' stations are missing (only a handful). They use a number of different station ids which will involve reading html to determine rss feed. 
# ** Remove all rtsp/mplayer/lame/tee dross when realaudio streams become obselete (not quite yet)
#
# Known Issues:
# * In ActivePerl/windows downloaded iPhone video files do not get renamed (remain with .partial.mov)
# * vlc does not quit after downloading an rtsp N96 video stream (ctrl-c is required) - need a --play-and-quit option if such a thing exists
#
#
# Changes 0.77 - 20080926
# * Added non-mandatory idv3 tagging support for MP3 files downloaded by new iPhone method using external id3 tools if available
# * Added --id3v2 option to specify non-default location of id3v2 binary
# * Added <fileprefix>, <ext> and <dir> to %prog so that it can be used in --command option
# * Tidied up definition of cache files
# * Cache files no longer get deleted upon get_iplayer upgrade
#
# Changes 0.76 - 20080924
# * A few cosmetic tweaks like the 'number of matches' appearing at the end on the programme listing
# * Set the 'type' option according to the index number specified (i.e. 1xxxx => radio, < 10000 => tv and > 19999 => podcast)
# * The programme cache is additionally read if an index is specified in its number range
#
# Changes 0.75 - 20080924
# * If an MP3 version of a radio programme is not available the default is to try to use the realaudio stream
# * --realaudio option prevents the downloading of radio MP3 streams
# * --mp3audio option ensures that realaudio stream is not used as a fallback for radio
# * A few cosmetic bug fixes
# * Check for existence of a PID when an index number is specified
# * Don't add empty pids to download_history file
# * Added --force-download option to override download history
# * Report final average download speed / bitrate / duration after successful downloads (not for rtsp streams)
# * Remove stdout logs - messes with stdout streaming in too many strange ways
# * Does not check download history if nowrite & stdout options are specified
#
# Changes 0.74 - 20080924
# * Changed --list-categories and --list-channels to use --list <element_name> where element name can be any element name in the %prog hash
# * Bugfix --streaminfo doesn't add to download history
# * Allow h.264 download subroutines to now also download mp3 audio for iphone radio
# * Added --realaudio option for radio downloads where mp3 download is not available
#
# Changes 0.73 - 20080922
# * Now remembers which PIDs/programmes have already been downloaded and will prevent downloading them after you delete the programme
# * The PID download history file is in ~/.get_iplayer/download_history
# * Added --outputradio --outputtv --outputpodcast to override --output so that different directories can be used for different programme types respectively
# * Added --list-categories and --list-channels support
# * Fixed a bug introduced in version 0.72 which --type=all would only result in --type=podcast
#
# Changes 0.72 - 20080919
# * time stamping of cache entries
# * Added --since option to see what was added since a number of hours ago (using above time stamps)
# * --flush now refreshes the cache rather than simply deleting it (retains timestamps)
#
# Changes 0.71 - 20080916
# * Workaround BBC World Service using non-standard PID format (not starting with b0)
# * Workaround BBC World Service HTTP redirects which contain extra whitespace and newlines around RTSP urls which mplayer does not like
# * Workaround BBC World Service where mediaselector metadata sets XML element kind="" instead of kind="audio"
#
# Changes 0.70 - 20080916
# * Added BBC World Service to iPlayer radio channels list
#

use Env qw[@PATH];
use Fcntl;
use File::Copy;
use File::Path;
use File::stat;
use Getopt::Long;
use HTML::Entities;
use HTTP::Cookies;
use HTTP::Headers;
use IO::Seekable;
use IO::Socket;
use LWP::ConnCache;
#use LWP::Debug qw(+);
use LWP::UserAgent;
use POSIX qw(mkfifo);
use strict;
use warnings;
use Time::Local;
use URI;

$|=1;
my %opt = ();


# Print to STDERR if not quiet unless verbose or debug
sub logger(@) {
	# Make sure quiet can be overridden by verbose and debug options
	print STDERR $_[0] if (! $opt{quiet}) || $opt{verbose} || $opt{debug};
}

sub usage {
	logger <<EOF;
get_iplayer v$version, Usage:
Search Programmes:  get_iplayer [<search options>] [<regex|index|pid|pidurl> ...]
Download files:     get_iplayer --get [<search options>] <regex|index|pid|pidurl> ...
                    get_iplayer --pid <pid|pidurl> [<options>]
Stream Downloads:   get_iplayer --stdout [<options>] <regex|index|pid|pidurl> | mplayer -cache 2048 -
Update get_iplayer: get_iplayer --update

Search Options:
 <regex|index|pid|url>         Search programme names based on given pattern
 -l, --long                    Additionally search in long programme descriptions / episode names
 --channel <regex>             Narrow search to matched channel(s)
 --category <regex>            Narrow search to matched categories
 --exclude-channel <regex>     Narrow search to exclude matched channel(s)
 --exclude-category <regex>    Narrow search to exclude matched catogories
 --type <radio|tv|podcast|all> Only search in these types of programmes (tv is default)
 --since <hours>               Limit search to programmes added to the cache in the last N hours

Display Options:
 -l, --long                    Display long programme descriptions / episode names and other data
 --terse                       Only show terse programme info (does not affect searching)
 -i, --info                    Show full programme metadata (only if number of matches < 50)
 --list <categories|channel>   Show a list of available categories/channels for the selected type and exit

Download Options:
 -g, --get                     Download matching programmes
 -x, --stdout                  Additionally stream to STDOUT (so you can pipe output to a player)
 -p, --proxy <url>             Web proxy URL spec
 --pid <pid|url>               Download an arbitrary pid that does not appear in the index
 --force-download              Ignore download history
 --realaudio                   Use the RealAudio radio stream and not the MP3 stream
 --mp3audio                    Use the MP3 radio stream for radio and dont fallback to the RealAudio stream
 --wav                         In radio realaudio mode output as wav and don't transcode to mp3
 --raw                         In radio realaudio mode output as raw realaudio and don't transcode to mp3
 --n96                         In TV mode download/stream low quality Nokia N96 H.264 stream (alpha)
 --bandwidth                   In radio realaudio mode specify the link bandwidth in bps for rtsp streaming (default 512000)
 --subtitles                   In TV mode, download subtitles into srt/SubRip format if available
 --suboffset <offset>          Offset the subtitle timestamps by the specified number of milliseconds
 -t, --test                    Test only - no download (will show programme type)
 
Output Options:
 -o, --output <dir>            Default Download output directory for all downloads
 --outputradio <dir>           Download output directory for radio
 --outputtv <dir>              Download output directory for tv
 --outputpodcast <dir>         Download output directory for podcasts
 -s, --subdir                  Downloaded files into Programme name subdirectory
 -n, --nowrite                 No writing of file to disk (use with -x to prevent a copy being stored on disk)
 -w, --whitespace              Keep whitespace (and escape chars) in filenames
 -q, --quiet                   No logging output
 -c, --command <command>       Run user command after successful download using args such as <pid>, <name> etc
 
Config Options:
 -f, --flush, --refresh        Refresh cache
 -e, --expiry <secs>           Cache expiry in seconds (default 4hrs)
 --symlink <file>              Create symlink to <file> once we have the header of the download
 --fxd <file>                  Create Freevo FXD XML in specified file
 --mythtv <file>               Create Mythtv streams XML in specified file
 --xml-channels                Create freevo/Mythtv menu of channels -> programme names -> episodes
 --xml-names                   Create freevo/Mythtv menu of programme names -> episodes
 --xml-alpha                   Create freevo/Mythtv menu sorted alphabetically by programme name
 --html <file>                 Create basic HTML index of programmes in specified file
 --mplayer <path>              Location of mplayer binary
 --lame <path>                 Location of lame binary
 --id3v2 <path>                Location of id3v2 binary
 --vlc <path>                  Location of vlc binary
 --streaminfo                  Returns all of the media stream urls of the programme(s)
 -v, --verbose                 Verbose
 -u, --update                  Update get_iplayer if a newer one exists
 -h, --help                    Help
 --save                        Save specified options as default in .get_iplayer/config
EOF
	exit 1;
}

# Get cmdline params
my $save;
# This is where all profile data/caches/cookies etc goes
my $profile_dir;
# This is where system-wide default options are specified
my $optfile_system;
# Options on unix-like systems
if ( defined $ENV{HOME} ) {
	$profile_dir = $ENV{HOME}.'/.get_iplayer';
	$optfile_system = '/etc/get_iplayer/options';

# Otherwise look for windows style file locations
} elsif ( defined $ENV{USERPROFILE} ) {
	$profile_dir = $ENV{USERPROFILE}.'/.get_iplayer';
	$optfile_system = $ENV{ALLUSERSPROFILE}.'/get_iplayer/options';
}
# Make profile dir if it doesnt exist
mkdir $profile_dir if ! -d $profile_dir;
# Personal options go here
my $optfile = "${profile_dir}/options";

# Parse options if we're not saving options (system-wide options are overridden by personal options)
if ( ! grep /\-\-save/, @ARGV ) {
	$opt{debug} = 1 if grep /\-\-debug/, @ARGV;
	read_options_file($optfile_system);
	read_options_file($optfile);
}

# Allow bundling of single char options
Getopt::Long::Configure ("bundling");
# cmdline opts take precedence
GetOptions(
	"help|h"			=> \$opt{help},
	"get|g"				=> \$opt{get},
	"long|l"			=> \$opt{long},
	"verbose|v"			=> \$opt{verbose},
	"flush|refresh|f"		=> \$opt{flush},
	"output|o=s"			=> \$opt{output},
	"outputtv|o=s"			=> \$opt{outputtv},
	"outputradio|o=s"		=> \$opt{outputradio},
	"outputpodcast|o=s"		=> \$opt{outputpodcast},
	"proxy|p=s"			=> \$opt{proxy},
	"stdout|stream|x"		=> \$opt{stdout},
	"subdirs|subdir|s"		=> \$opt{subdir},
	"no-write|nowrite|n"		=> \$opt{nowrite},
	"expiry|e=n"			=> \$opt{expiry},
	"test|t"			=> \$opt{test},
	"whitespace|ws|w"		=> \$opt{whitespace},
	"update|u"			=> \$opt{update},
	"debug"				=> \$opt{debug},
	"channel=s"			=> \$opt{channel},
	"category=s"			=> \$opt{category},
	"q|quiet"			=> \$opt{quiet},
	"symlink|freevo=s"		=> \$opt{symlink},
	"fxd=s"				=> \$opt{fxd},
	"mythtv=s"			=> \$opt{mythtv},
	"xml-channels|fxd-channels"	=> \$opt{xmlchannels},
	"xml-names|fxd-names"		=> \$opt{xmlnames},
	"xml-alpha|fxd-alpha"		=> \$opt{xmlalpha},
	"html=s"			=> \$opt{html},
	"terse"				=> \$opt{terse},
	"pid=s"				=> \$opt{pid},
	"type=s"			=> \$opt{type},
	"exclude-category=s"		=> \$opt{excludecategory},
	"exclude-channel=s"		=> \$opt{excludechannel},
	"i|info"			=> \$opt{info},
	"c|command=s"			=> \$opt{command},
	"mplayer=s"			=> \$opt{mplayer},
	"lame=s"			=> \$opt{lame},
	"id3v2=s"			=> \$opt{id3v2},
	"vlc=s"				=> \$opt{vlc},
	"n96"				=> \$opt{n96},
	"realaudio"			=> \$opt{realaudio},
	"mp3audio"			=> \$opt{mp3audio},
	"force-download"		=> \$opt{forcedownload},
	"wav"				=> \$opt{wav},
	"raw"				=> \$opt{raw},
	"bandwidth=n"			=> \$opt{bandwidth},
	"subtitles"			=> \$opt{subtitles},
	"suboffset=n"			=> \$opt{suboffset},
	"streaminfo"			=> \$opt{streaminfo},
	"since=n"			=> \$opt{since},
	"list=s"			=> \$opt{list},
	"save"				=> \$save,
) || die usage();
usage() if $opt{help};

# Save opts if specified
save_options_file($optfile) if $save;

# Default to type=tv
$opt{type} = 'tv' if ! $opt{type};
# Expand 'all' to various prog types
$opt{type} = 'tv,radio,podcast' if $opt{type} =~ /(all|any)/i;
# Ensure lowercase
$opt{type} = lc( $opt{type} );

# Options
my %download_dir	= (
	'tv'		=> $opt{outputtv} || $opt{output} || $ENV{IPLAYER_OUTDIR} || '.',
	'radio'		=> $opt{outputradio} || $opt{output} || $ENV{IPLAYER_OUTDIR} || '.',
	'podcast'	=> $opt{outputpodcast} || $opt{output} || $ENV{IPLAYER_OUTDIR} || '.',
);
my %cachefile = (
	'tv'		=> "${profile_dir}/tv.cache",
	'radio'		=> "${profile_dir}/radio.cache",
	'podcast'	=> "${profile_dir}/podcast.cache",
);
my $get_iplayer_stream	= 'get_iplayer_freevo_wrapper';	# Location of wrapper script for streaming with mplayer/xine on freevo
my $historyfile		= "${profile_dir}/download_history";
my $cookiejar		= "${profile_dir}/cookies";
my $namedpipe 		= "${profile_dir}/namedpipe.$$";
my $cache_secs 		= $opt{expiry} || 14400;
my $lwp_request_timeout	= 20;
my $info_limit		= 40;
my $mplayer		= $opt{mplayer} || 'mplayer';
my $mplayer_opts	= '-nolirc';
$mplayer_opts		.= ' -really-quiet' if $opt{quiet};
my $lame		= $opt{lame} || 'lame';
my $lame_opts		= '-f ';
$lame_opts		.= '--quiet ' if $opt{quiet};
my $vlc			= $opt{vlc} || 'cvlc';
my $vlc_opts		= '-vv';
my $id3v2		= $opt{id3v2} || 'id3v2';
my $tee			= 'tee';
my $bandwidth		= $opt{bandwidth} || 512000; # Download bandwidth bps used for rtsp streams
# Set quiet, test and get options if we're asked for streaminfo
if ( $opt{streaminfo} ) {
	$opt{test} = 1;
	$opt{get} = 1;
	$opt{quiet} = 1;
}

# URLs
my $search_page_prefix		= 'http://www.bbc.co.uk/iplayer/atoz/?filter=azgroup%3A*&start=';
my $channel_feed_url		= 'http://feeds.bbc.co.uk/iplayer'; # /$channel/list/limit/200
my $pid_page_url_prefix		= 'http://www.bbc.co.uk/iplayer/episode/';
my $web_bug_2_url		= 'http://www.bbc.co.uk/iplayer/framework/img/o.gif?';
my $audio_download_prefix	= 'http://www.bbc.co.uk/mediaselector/4/mtis/stream';
my $video_download_prefix	= 'http://www.bbc.co.uk/mediaselector/3/auth/iplayer_streaming_http_mp4';
my $prog_page_prefix		= 'http://www.bbc.co.uk/programmes';
my $thumbnail_prefix		= 'http://www.bbc.co.uk/iplayer/images/episode';
my $metadata_xml_prefix		= 'http://www.bbc.co.uk/iplayer/metafiles/episode'; # /${pid}.xml
my $metadata_mobile_prefix	= 'http://www.bbc.co.uk/iplayer/widget/episodedetail/episode'; # /${pid}/template/mobile/service_type/tv/
my $podcast_index_url		= 'http://www.bbc.co.uk/radio/opml/bbc_podcast_opml.xml';
my $version_url			= 'http://linuxcentre.net/get_iplayer/VERSION-get_iplayer';
my $update_url			= 'http://linuxcentre.net/get_iplayer/get_iplayer';

my %channels;
$channels{tv} = {
	'bbc_one'				=> 'tv|BBC One',
	'bbc_two'				=> 'tv|BBC Two',
	'bbc_three'				=> 'tv|BBC Three',
	'bbc_four'				=> 'tv|BBC Four',
	'cbbc'					=> 'tv|CBBC',
	'cbeebies'				=> 'tv|CBeebies',
	'bbc_news24'				=> 'tv|BBC News 24',
	'bbc_parliament'			=> 'tv|BBC Parliament',
	'bbc_one_northern_ireland'		=> 'tv|BBC One Northern Ireland',
	'bbc_one_scotland'			=> 'tv|BBC One Scotland',
	'bbc_one_wales'				=> 'tv|BBC One Wales',
	'bbc_webonly'				=> 'tv|BBC Web Only',
	'bbc_hd'				=> 'tv|BBC HD',
	'categories/news/tv'			=> 'tv|BBC News',
	'categories/sport/tv'			=> 'tv|BBC Sport',
#	'categories/tv'				=> 'tv|All',
#	'categories/signed/tv'			=> 'tv|Signed',
};

$channels{radio} = {
	'bbc_1xtra'				=> 'radio|BBC 1Xtra',
	'bbc_radio_one'				=> 'radio|BBC Radio 1',
	'bbc_radio_two'				=> 'radio|BBC Radio 2',
	'bbc_radio_three'			=> 'radio|BBC Radio 3',
	'bbc_radio_four'			=> 'radio|BBC Radio 4',
	'bbc_radio_five_live'			=> 'radio|BBC Radio 5 live',
	'bbc_radio_five_live_sports_extra'	=> 'radio|BBC 5 live Sports Extra',
	'bbc_6music'				=> 'radio|BBC 6 Music',
	'bbc_7'					=> 'radio|BBC 7',
	'bbc_asian_network'			=> 'radio|BBC Asian Network',
	'bbc_radio_foyle'			=> 'radio|BBC Radio Foyle',
	'bbc_radio_scotland'			=> 'radio|BBC Radio Scotland',
	'bbc_radio_ulster'			=> 'radio|BBC Radio Ulster',
	'bbc_radio_wales'			=> 'radio|BBC Radio Wales',
	'bbc_world_service'			=> 'radio|BBC World Service',
#	'categories/radio'			=> 'radio|All',
};


# User Agents
my %user_agent = (
  	coremedia	=> 'Apple iPhone v1.1.1 CoreMedia v1.0.0.3A110a',
  	safari		=> 'Mozilla/5.0 (iPhone; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A110a Safari/419.3',
  	update		=> "get_iplayer updater (v${version} - $^O)",
  	desktop		=> 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-GB; rv:1.9) Gecko/2008052906 Firefox/3.0',
);

# Setup signal handlers
$SIG{INT} = $SIG{PIPE} =\&cleanup;


# Sanity check some conflicting options
if ($opt{nowrite} && (!$opt{stdout})) {
	logger "ERROR: Cannot download to nowhere\n";
	exit 1;
}

# Programme data structure
# $prog{$pid} = {
#	'index'		=> <index number>,
#	'name'		=> <programme short name>,
#	'episode'	=> <Episode info>,
#	'desc'		=> <Long Description>,
#	'available'	=> <Date/Time made available or remaining>,
#	'duration'	=> <duration in HH:MM:SS>
#	'versions'	=> <comma separated list of versions, e.g Original, Signed>
#	'thumbnail'	=> <programme thumbnail url>
#	'channel	=> <channel>
#	'categories'	=> <Comma separtaed list of categories>
# 	'type'		=> <Type: tv, radio or podcast>
#	'timeadded'	=> <timestamp when programme was added to cache>
#	'longname'	=> <Long name (only parsed in stage 1 download)>,
#	'version'	=> <selected version e.g Original, Signed, etc - only set before d/load>
#	'filename'	=> <Path and Filename of saved file - set only while downloading>
#	'dir'		=> <Filename Directory of saved file - set only while downloading>
#	'fileprefix'	=> <Filename Prefix of saved file - set only while downloading>
#	'ext'		=> <Filename Extension of saved file - set only while downloading>
#};
my %prog;
# Hash to obtain pid given an index
my %index_pid;
my $now;
my $childpid;

# Web proxy
my $proxy_url = $opt{proxy} || $ENV{HTTP_PROXY} || $ENV{http_proxy} || '';
logger "INFO: Using Proxy $proxy_url\n" if $proxy_url;

# Update this script if required
if ($opt{update}) {
	update_script();
}

# Check for valid dload dirs or create them
for ( keys %download_dir ) {
	if ( ! -d $download_dir{$_} ) {
		logger "INFO: Created directory $download_dir{$_}\n";
		mkpath($download_dir{$_});
	}
}


# Get stream links from BBC iplayer site or from cache (also populates all hashes) specified in --type option
get_links( $_ ) for split /,/, $opt{type};


# List elements (i.e. 'channel' 'categories') if required and exit
if ( $opt{list} ) {
	list_unique_element_counts( $opt{list} );
	exit 0;
}

# Write HTML and XML files if required
create_html( sort {$a <=> $b} keys %index_pid ) if $opt{html};
create_xml( $opt{fxd}, sort {$a <=> $b} keys %index_pid ) if $opt{fxd};
create_xml( $opt{mythtv}, sort {$a <=> $b} keys %index_pid ) if $opt{mythtv};

# Get arbitrary pid
if ( $opt{pid} ) {
	# Remove any url parts from the pid
	$opt{pid} =~ s/^.*(b0[a-z,0-9]{6}).*$/$1/g;
	# Retry loop
	my $count;
	my $retries = 3;
	my $retcode;
	exit 1 if ( ! $opt{streaminfo} ) && check_download_history( $opt{pid} );
	while ( $count < $retries && ($retcode = download_programme( $opt{pid} )) eq 'retry' ) {
		logger "WARNING: Retrying download for PID $opt{pid}\n";
		$count++;
	}
	# Add to history and Run post download command if download was successful
	if ($retcode == 0) {
		add_to_download_history( $opt{pid} );
		run_user_command( $opt{pid}, $opt{command} ) if $opt{command};
	}	
	exit 0;
}

# Assume search term is '.*' if nothing is specified - i.e. lists all programmes
push @ARGV, '.*' if ! $ARGV[0];

# Parse remaining args
my @match_list;
for ( @ARGV ) {
	chomp();

	# If Numerical value < 30000
	if ( /^[\d]+$/ && $_ < 30000) {
		push @match_list, $_;

	# If PID then find matching programmes with this PID
	} elsif ( /^.*b0[a-z,0-9]{6}.*$/ ) {
		s/^.*(b0[a-z,0-9]{6}).*$/$1/g;
		push @match_list, get_regex_matches( $1 );

	# Else assume this is a programme name regex
	} else {
		push @match_list, get_regex_matches( $_ );
	}
}

# De-dup matches and retain order
my %seen = ();
my @unique = grep { ! $seen{ $_ }++ } @match_list;
@match_list = @unique;

# Go get the cached data for other programme types if the index numbers require it
my %require;
for ( @match_list ) {
	$require{tv} = 1 if $_ >= 1 && $_ < 10000 && ( ! $require{tv} ) && $opt{type} !~ /tv/;
	$require{radio} = 1 if $_ >= 10000 && $_ < 20000 && ( ! $require{radio} ) && $opt{type} !~ /radio/;
	$require{podcast} = 1 if $_ >= 20000 && $_ < 30000 && ( ! $require{podcast} ) && $opt{type} !~ /podcast/;
}
# Get extra required programme caches
logger "INFO: Additionally getting cached programme data for ".(join ', ', keys %require)."\n" if %require > 0;
# Get stream links from BBC iplayer site or from cache (also populates all hashes)
for (keys %require) {
	# Get $_ stream links
	get_links( $_ );
	# Add new prog types to the type option
	$opt{type} .= ",$_";
}

# Display list for download
logger "Matches:\n" if @match_list;
@match_list = list_progs( @match_list );

# Do the downloads based on list of index numbers if required
if ( $opt{get} || $opt{stdout} ) {
	for (@match_list) {
		# Retry loop
		my $count = 0;
		my $retries = 3;
		my $retcode;
		my $pid = $index_pid{$_};
		next if ( ! $opt{streaminfo} ) && check_download_history( $pid );
		# Skip and warn if there is no pid
		if ( ! $pid ) {
			logger "ERROR: No PID for index $_ (try using --type option ?)\n";
			next;
		}
		while ( $count < $retries && $pid && ($retcode = download_programme( $pid )) eq 'retry' ) {
			logger "WARNING: Retrying download for '$prog{$pid}{name} - $prog{$pid}{episode}'\n";
			$count++;
		}
		# Add to history, tag file, and run post download command if download was successful
		if ($retcode == 0) {
			add_to_download_history( $pid );
			tag_file( $pid );
			run_user_command( $pid, $opt{command} ) if $opt{command};
		}
	}
}

exit 0;




# Lists progs given an array of index numbers, also retuens an array with non-existent entries removed
sub list_progs {
	my $ua;
	my @checked;
	# Setup user agent for a persistent connection to get programme metadata
	if ( $opt{info} ) {
		$ua = LWP::UserAgent->new;
		$ua->timeout([$lwp_request_timeout]);
		$ua->proxy( ['http'] => $proxy_url );
		$ua->agent( $user_agent{desktop} );
		$ua->conn_cache(LWP::ConnCache->new());
		# Truncate array if were lisiting info and > $info_limit entries are requested - be nice to the beeb!
		if ( $#_ >= $info_limit ) {
			$#_ = $info_limit - 1;
			logger "WARNING: Only processing the first $info_limit matches\n";
		}
	}

	for (@_) {
		my $pid = $index_pid{$_};
		next if ! $pid;
		list_prog_entry( $pid, '' );
		push @checked, $_;
		logger get_pid_metadata( $ua, $pid )."\n" if $opt{info};
	}
	logger "\n";

	logger "INFO: ".($#checked + 1)." Matching Programmes\n";
	return @checked;
}



# Display a line containing programme info (using long, terse, and type options)
sub list_prog_entry {
	my ( $pid, $prefix ) = ( @_ );
	my $type = '';
	$type = "$prog{$pid}{type}, " if $opt{type} !~ /^(tv|radio|podcast)$/i;
	# Remove some info depending on type
	my $optional;
	$optional = ", '$prog{$pid}{channel}', $prog{$pid}{categories}, $prog{$pid}{versions}" if $prog{$pid}{type} eq 'tv';
	$optional = ", '$prog{$pid}{channel}', $prog{$pid}{categories}" if $prog{$pid}{type} eq 'radio';
	$optional = ", '$prog{$pid}{available}', '$prog{$pid}{channel}', $prog{$pid}{categories}" if $prog{$pid}{type} eq 'podcast';
	# Display based on output options
	if ( $opt{long} ) {
		my @time = gmtime( time() - $prog{$pid}{timeadded} );
		logger "${prefix}$prog{$pid}{index}:\t${type}$prog{$pid}{name} - $prog{$pid}{episode}${optional}, $time[7] days $time[2] hours ago - $prog{$pid}{desc}\n";
	} elsif ( $opt{terse} ) {
		logger "${prefix}$prog{$pid}{index}:\t${type}$prog{$pid}{name} - $prog{$pid}{episode}\n";
	} else {
		logger "${prefix}$prog{$pid}{index}:\t${type}$prog{$pid}{name} - $prog{$pid}{episode}${optional}\n";
	}
	return 0;
}



# Get matching programme index numbers using supplied regex
sub get_regex_matches {
	my $download_regex = shift;
	my %download_hash;
	my $channel_regex = $opt{channel} || '.*';
	my $category_regex = $opt{category} || '.*';
	my $channel_exclude_regex = $opt{excludechannel} || '^ROGUE$';
	my $category_exclude_regex = $opt{excludecategory} || '^ROGUE$';
	my $since = $opt{since} || 99999;
	my $now = time();
		
	for (keys %index_pid) {
		my $pid = $index_pid{$_};

		# Only include programmes matching channels and category regexes
		if ( $prog{$pid}{channel} =~ /$channel_regex/i
		  && $prog{$pid}{categories} =~ /$category_regex/i
		  && $prog{$pid}{channel} !~ /$channel_exclude_regex/i
		  && $prog{$pid}{categories} !~ /$category_exclude_regex/i
		  && $prog{$pid}{timeadded} >= $now - ($since * 3600)
		) {

			# Search prognames/pids while excluding channel_regex and category_regex
			$download_hash{$_} = 1 if (
				$prog{$pid}{name} =~ /$download_regex/i
				|| ( $pid =~ /$download_regex/i && $download_regex =~ /b00/ )
				|| ( $pid =~ /$download_regex/i && $download_regex =~ /b00/ )
			);
			# Also search long descriptions and episode data if -l is specified
			$download_hash{$_} = 1 if (
				$opt{long} 
				&& 
				( $prog{$pid}{desc} =~ /$download_regex/i
				  || $prog{$pid}{episode} =~ /$download_regex/i
				)
			);
		}
	}
	return sort {$a <=> $b} keys %download_hash;
}


# get_links_atom (%channels)
sub get_links_atom {
	my $type = shift;
	my %channels = %{$_[0]};

	my $xml;
	my $feed_data;
	my $res;
	logger "INFO: Getting $type Index Feeds\n";
	# Setup User agent
	my $ua = LWP::UserAgent->new;
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->agent( $user_agent{desktop} );
	$ua->conn_cache(LWP::ConnCache->new());

	# Download index feed
	# Sort feeds so that category based feeds are done last - this makes sure that the channels get defined correctly if there are dups
	my @channel_list;
	push @channel_list, grep !/categor/, keys %channels;
	push @channel_list, grep  /categor/, keys %channels;
	for ( @channel_list ) {

		my $url = "${channel_feed_url}/$_/list/limit/400";
		logger "DEBUG: Getting feed $url\n" if $opt{verbose};
		$xml = request_url_retry($ua, $url, 3, '.', "WARNING: Failed to get programme index feed for $_ from iplayer site\n");
		logger "INFO: Got ".(grep /<entry/, split /\n/, $xml)." programmes\n" if $opt{verbose};
		decode_entities($xml);	
		
		# Feed as of August 2008
		#	 <entry>
		#	   <title type="text">Bargain Hunt: Series 18: Oswestry</title>
		#	   <id>tag:feeds.bbc.co.uk,2008:PIPS:b0088jgs</id>
		#	   <updated>2008-07-22T00:23:50Z</updated>
		#	   <content type="html">
		#	     &lt;p&gt;
		#	       &lt;a href=&quot;http://www.bbc.co.uk/iplayer/episode/b0088jgs?src=a_syn30&quot;&gt;
		#		 &lt;img src=&quot;http://www.bbc.co.uk/iplayer/images/episode/b0088jgs_150_84.jpg&quot; alt=&quot;Bargain Hunt: Series 18: Oswestry&quot; /&gt;
		#	       &lt;/a&gt;
		#	     &lt;/p&gt;
		#	     &lt;p&gt;
		#	       The teams are at an antiques fair in Oswestry showground. Hosted by Tim Wonnacott.
		#	     &lt;/p&gt;
		#	   </content>
		#	   <category term="Factual" />
		#	   <category term="TV" />
		#	   <link rel="via" href="http://www.bbc.co.uk/iplayer/episode/b0088jgs?src=a_syn30" type="text/html" title="Bargain Hunt: Series 18: Oswestry" />
		#       </entry>
		#

		### New Feed
		#  <entry>
		#    <title type="text">House of Lords: 02/07/2008</title>
		#    <id>tag:bbc.co.uk,2008:PIPS:b00cd5p7</id>
		#    <updated>2008-06-24T00:15:11Z</updated>
		#    <content type="html">
		#      <p>
		#	<a href="http://www.bbc.co.uk/iplayer/episode/b00cd5p7?src=a_syn30">
		#	  <img src="http://www.bbc.co.uk/iplayer/images/episode/b00cd5p7_150_84.jpg" alt="House of Lords: 02/07/2008" />
		#	</a>
		#      </p>
		#      <p>
		#	House of Lords, including the third reading of the Health and Social Care Bill. 1 July.
		#      </p>
		#    </content>
		#    <category term="Factual" scheme="urn:bbciplayer:category" />
		#    <link rel="via" href="http://www.bbc.co.uk/iplayer/episode/b00cd5p7?src=a_syn30" type="application/atom+xml" title="House of Lords: 02/07/2008">
		#    </link>
		#  </entry>

		# Parse XML

		# get list of entries within <entry> </entry> tags
		my @entries = split /<entry>/, $xml;
		# Discard first element == header
		shift @entries;

		my ( $name, $episode, $desc, $pid, $available, $channel, $duration, $thumbnail, $type );
		foreach my $entry (@entries) {

			my $entry_flat = $entry;
			$entry_flat =~ s/\n/ /g;

			# <id>tag:bbc.co.uk,2008:PIPS:b008pj3w</id>
			$pid = $1 if $entry =~ m{<id>.*PIPS:(.+?)</id>};

			# Skip if this pid is a duplicate
			if ( defined $prog{$pid} ) {
				logger "WARNING: '$pid, $prog{$pid}{name} - $prog{$pid}{episode}, $prog{$pid}{channel}' already exists (this channel = $_)\n" if $opt{verbose};
				next;
			}

			# parse name: episode, e.g. Take a Bow: Street Feet on the Farm
			$name = $1 if $entry =~ m{<title\s*.*?>\s*(.*?)\s*</title>};
			$episode = $name;
			$name =~ s/^(.*): .*$/$1/g;
			$episode =~ s/^.*: (.*)$/$1/g;

			# This is not the availability!
			# <updated>2008-06-22T05:01:49Z</updated>
			#$available = get_available_time_string( $1 ) if $entry =~ m{<updated>(\d{4}\-\d\d\-\d\dT\d\d:\d\d:\d\d.).*?</updated>};

			#<p>    House of Lords, including the third reading of the Health and Social Care Bill. 1 July.   </p>    </content>
			$desc = $1 if $entry =~ m{<p>\s*(.*?)\s*</p>\s*</content>};

			# Parse the categories into hash
			# <category term="Factual" />
			my @category;
			for my $line ( grep /<category/, (split /\n/, $entry) ) {
				push @category, $1 if $line =~ m{<category\s+term="(.+?)"};
			}

			# Extract channel and type
			($type, $channel) = (split /\|/, $channels{$_})[0,1];

			logger "DEBUG: '$pid, $name - $episode, $channel'\n" if $opt{debug};

			# build data structure
			$prog{$pid} = {
				'name'		=> $name,
				'versions'	=> 'Original',
				'episode'	=> $episode,
				'desc'		=> $desc,
				'available'	=> 'Unknown',
				'duration'	=> 'Unknown',
				'thumbnail'	=> "${thumbnail_prefix}/${pid}_150_84.jpg",
				'channel'	=> $channel,
				'categories'	=> join(',', @category),
				'type'		=> $type,
			};
		}
	}
	logger "\n";
	return 0;
}



# Populates the index field of the prog hash as well as creating the %index_pid hash
# Should be run after getting any link lists
sub sort_indexes {

	# Add index field based on alphabetical sorting by prog name
	my %index;
	$index{tv} = 1;
	
	# Start index counter at 10001 for radio progs
	$index{radio} = 10001;

	# Start index counter at 20001 for podcast progs
	$index{podcast} = 20001;

	my @prog_pid;

	# Create unique array of '<progname|pid>'
	push @prog_pid, "$prog{$_}{name}|$_" for (keys %prog);

	# Sort by progname and index 
	for (sort @prog_pid) {
		# Extract pid
		my $pid = (split /\|/)[1];
		my $type = $prog{$pid}{type};
		$index_pid{ $index{$type} } = $pid;
		$prog{$pid}{index} = $index{$type};
		$index{$type}++;
	}
	return 0;
}



# Uses: $podcast_index_url
# get_podcast_links ()
sub get_podcast_links {

	my $xml;
	my $res;
	logger "INFO: Getting Podcast Index\n";
	# Setup User agent
	my $ua = LWP::UserAgent->new;
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->agent( $user_agent{safari} );
	$ua->conn_cache(LWP::ConnCache->new());
	
	# Method
	# (HTML: http://www.bbc.co.uk/radio/podcasts/directory/station/radio1)
	# http://www.bbc.co.uk/radio/podcasts/ip/lists/$channel.sssi => 
	# http://www.bbc.co.uk/radio/podcasts/$name/assets/iphone_keepnet.sssi => (rewrite URL)
	# ( http://downloads.bbc.co.uk/podcasts/radio/$name/rss.xml for some progs!)
	# http://downloads.bbc.co.uk/podcasts/$channel/$name/rss.xml =>

	# Method
	# $podcast_index_url (gets list of rss feeds for each podcast prog) =>
	# http://downloads.bbc.co.uk/podcasts/$channel/$name/rss.xml =>
	
	# Get top-level podcast index (OPML)
	#  <li class="li_with_image">
	#    <a href="/radio/podcasts/trintro/assets/iphone_keepnet.sssi">
	#      <div class="list-link">
	#	<span class="img">
	#	  <img class="podcast_image"
	#	  src="http://www.bbc.co.uk/radio/podcasts/trintro/assets/_70x70.jpg" />
	#	</span>
	#	<p class="podcast_title">Tom Robinson Introducing...</p>
	#      </div>
	#    </a>
	#  </li>

	# Download index feed
	my ( $name, $title );


	my $opmldata = request_url_retry($ua, $podcast_index_url, 3, '.', "WARNING: Failed to get prodcast index from site\n");
	$opmldata =~ s/\n/ /g;

	# All channels with RSS feeds have an element like: <outline text="scotland" fullname="BBC Radio Nan Gaidheal">
	my @channel_data = split /(<outline\s+text="[^"]+?"\s+fullname="[^"]+?"\s*>.*?<\/outline>)/, $opmldata;

	my $service;
	for (@channel_data) {
		# Extract channel name, service and rss feed data
		my ($channel, $data);
		$channel = $1 if m{<outline\s+text="[^"]+?"\s+fullname="([^"]+?)"\s*>};
		$data = $1 if m{<outline\s+text="[^"]+?"\s+fullname="[^"]+?"\s*>(.*?)<\/outline>};

		# Skip if there is no feed data for channel
		next if ! ($channel || $data);
			
		#print "SERVICE=$service, CHANNEL=$channel, DATA=\n$data\n";

		# Every RSS feed has an extry like below (all in a text block - not formatted like below)
		# <outline 
		#	type="rss" 
		#	imageHref="http://www.bbc.co.uk/radio/podcasts/scotlife/assets/_300x300.jpg" 
		#	xmlUrl="http://downloads.bbc.co.uk/podcasts/scotland/scotlife/rss.xml" 
		#	imageHrefTVSafe="" 
		#	text="Scottish Life" 
		#	keyname="scotlife" 
		#	active="true" 
		#	allow="all" 
		#	networkName="" 
		#	networkId="" 
		#	typicalDurationMins="0" 
		#	page="http://www.bbc.co.uk/radioscotland" 
		#	flavour="Whole Programme" 
		#	rsstype="" 
		#	rssenc="" 
		#	language="en" 
		#	description="Compelling personal stories from every possible walk of life, Scottish Life is a weekly digest of some of the most touching, engaging, funny and infuriating experiences we’ve heard about on BBC Radio Scotland.  Working life, family life, love life and leisure life, Scottish Life has it all!" 
		#	bbcgenres=""
		# />

		# For each rss feed, create an entry in %podcast_channel_prog (name => feed_url)
		my %podcast_channel_prog;
		my @podcast_channel_list = split /<outline\s+type="rss"/, $data;
		for ( @podcast_channel_list ) {
			my ($name, $xmlurl);
			# Get podcast id name
			$name = $1 if m{text="(.+?)"};
			# Get nice name
			$xmlurl = $1 if m{xmlUrl="(.+?)"};
			# Skip if not valid
			next if ! ($name && $xmlurl);
			$podcast_channel_prog{ $name } = $xmlurl;
			#print "CHANNEL=$channel\tSERVICE: $service\tNAME: $name\nXMLURL=$xmlurl\n";
		}

		# Loop thru each programme name
		for ( keys %podcast_channel_prog ) {
			my ( $name, $episode, $desc, $pid, $available, $duration, $thumbnail );

			# Get RSS feeds for each podcast programme
			my $url = $podcast_channel_prog{$_};
	
			logger "DEBUG: Getting podcast feed $url\n" if $opt{verbose};
			$xml = request_url_retry($ua, $url, 3, '.', "WARNING: Failed to get podcast feed for $service / $_ from iplayer site\n") if $opt{verbose};
			$xml = request_url_retry($ua, $url, 3, '.', '') if ! $opt{verbose};
			# Dirty hack cos some progs are under service=radio :-|
			if (! $xml) {
				my $url = "http://downloads.bbc.co.uk/podcasts/radio/$_/rss.xml";
				$xml = request_url_retry($ua, $url, 3, '.', "WARNING: Failed to get podcast feed for radio / $_ from iplayer site\n") if $opt{verbose};
				$xml = request_url_retry($ua, $url, 3, '.', '') if ! $opt{verbose};
			}
			# skip if no data
			next if ! $xml;

			logger "INFO: Got ".(grep /<media:content/, split /<item>/, $xml)." programmes\n" if $opt{verbose};
			decode_entities($xml);
	
			# First entry is channel data
			# <?xml version="1.0" encoding="utf-8"?>
			#<rss xmlns:media="http://search.yahoo.com/mrss/"
			#xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"
			#version="2.0">
			#  <channel>
			#    <title>Stuart Maconie's Freak Zone</title>
			#    <link>http://www.bbc.co.uk/6music/shows/freakzone/</link>
			#    <description>Weekly highlights from Stuart Maconie's
			#    ...podcast is only available in the UK.</description>
			#    <itunes:summary>Weekly highlights from Stuart Maconie's
			#    ...podcast is only available in the UK.</itunes:summary>
			#    <itunes:author>BBC 6 Music</itunes:author>
			#    <itunes:owner>
			#      <itunes:name>BBC</itunes:name>
			#      <itunes:email>podcast.support@bbc.co.uk</itunes:email>
			#    </itunes:owner>
			#    <language>en</language>
			#    <ttl>720</ttl>
			#    <image>
			#      <url>
			#      http://www.bbc.co.uk/radio/podcasts/freakzone/assets/_300x300.jpg</url>
			#      <title>Stuart Maconie's Freak Zone</title>
			#      <link>http://www.bbc.co.uk/6music/shows/freakzone/</link>
			#    </image>
			#    <itunes:image href="http://www.bbc.co.uk/radio/podcasts/freakzone/assets/_300x300.jpg" />
			#    <copyright>(C) BBC 2008</copyright>
			#    <pubDate>Sun, 06 Jul 2008 20:00:05 +0100</pubDate>
			#    <itunes:category text="Music" />
			#    <itunes:keywords>Stewart Maconie, Macconie, freekzone,
			#    freakzone, macoonie</itunes:keywords>
			#    <media:keywords>Stewart Maconie, Macconie, freekzone,
			#    freakzone, macoonie</media:keywords>
			#   <itunes:explicit>no</itunes:explicit>
			#    <media:rating scheme="urn:simple">nonadult</media:rating>
	
			# Parse XML
	
			# get list of entries within <entry> </entry> tags
			my @entries = split /<item>/, $xml;
			# first element == <channel> header
			my $header = shift @entries;

			# Get podcast name
			$name = $1 if $header =~ m{<title>\s*(.+?)\s*</title>};
	
			# Parse the categories into hash
			# <itunes:category text="Music" />
			my @category;
			for my $line ( grep /<itunes:category/, (split /\n/, $header) ) {
				push @category, $1 if $line =~ m{<itunes:category\s+text="\s*(.+?)\s*"};
			}
	
			# Get thumbnail from header
			# <itunes:image href="http://www.bbc.co.uk/radio/podcasts/freakzone/assets/_300x300.jpg" />
			$thumbnail = $1 if $header =~ m{<itunes:image href="\s*(.+?)\s*"};

			# Followed by items:
			#    <item>
			#      <title>FreakZone: C'est Stuart avec le Professeur Spear et le
			#      pop francais?</title>
			#      <description>Stuart and Justin discuss the sub-genre of
			#      French 'cold wave' in this week's module.</description>
			#      <itunes:subtitle>Stuart and Justin discuss the sub-genre of
			#      French 'cold wave' in this week's
			#      module....</itunes:subtitle>
			#      <itunes:summary>Stuart and Justin discuss the sub-genre of
			#      French 'cold wave' in this week's module.</itunes:summary>
			#      <pubDate>Sun, 06 Jul 2008 20:00:00 +0100</pubDate>
			#      <itunes:duration>14:23</itunes:duration>
			#      <enclosure url="http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3"
			#      length="13891916" type="audio/mpeg" />
			#      <guid isPermaLink="false">
			#      http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3</guid>
			#      <link>
			#      http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3</link>
			#      <media:content url="http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3"
			#      fileSize="13891916" type="audio/mpeg" medium="audio"
			#      expression="full" duration="863" />
			#      <itunes:author>BBC 6 Music</itunes:author>
			#    </item>
	
			foreach my $entry (@entries) {
	
				my $entry_flat = $entry;
				$entry_flat =~ s/\n/ /g;
	
				# Use the link as a guid
				# <link>   http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3</link>
				$pid = $1 if $entry =~ m{<link>\s*(.+?)</link>};
	
				# Skip if this pid is a duplicate
				if ( defined $prog{$pid} ) {
					logger "WARNING: '$pid, $prog{$pid}{name} - $prog{$pid}{episode}, $prog{$pid}{channel}' already exists (this channel = $_)\n" if $opt{verbose};
					next;
				}
	
				# parse episode
				# <title>FreakZone: C'est Stuart avec le Professeur Spear et le pop francais?</title>
				$episode = $1 if $entry =~ m{<title>\s*(.*?)\s*</title>};
	
				# <pubDate>Sun, 06 Jul 2008 20:00:00 +0100</pubDate>
				$available = $1 if $entry =~ m{<pubDate>\s*(.*?)\s*</pubDate>};
	
				# <description>Stuart and Justin discuss the sub-genre of French 'cold wave' in this week's module.</description>
				$desc = $1 if $entry =~ m{<description>\s*(.*?)\s*</description>};
	
				# Duration
				$duration = $1 if $entry =~ m{<itunes:duration>\s*(.*?)\s*</itunes:duration>};
	
				# build data structure
				$prog{$pid} = {
					'name'		=> $name,
					'versions'	=> 'Original',
					'episode'	=> $episode,
					'desc'		=> $desc,
					'available'	=> $available,
					'duration'	=> $duration,
					'thumbnail'	=> $thumbnail,
					'channel'	=> $channel,
					'categories'	=> join(',', @category),
					'type'		=> 'podcast',
				};
			}
		}
	}
	logger "\n";
	return 0;
}



# Feed info:
#	# Also see http://derivadow.com/2008/07/18/interesting-bbc-data-to-hack-with/
#	# All podcasts menu (iphone)
#	http://www.bbc.co.uk/radio/podcasts/ip/
#	# All radio1 podcasts
#	http://www.bbc.co.uk/radio/podcasts/ip/lists/radio1.sssi
#	# All radio1 -> moyles podcasts
#	http://www.bbc.co.uk/radio/podcasts/moyles/assets/iphone_keepnet.sssi
#	# RSS Feed (indexed from?)
#	http://downloads.bbc.co.uk/podcasts/radio1/moyles/rss.xml
#	# aod by channel see http://docs.google.com/View?docid=d9sxx7p_38cfsmxfcq
#	# http://www.bbc.co.uk/radio/aod/availability/<channel>.xml
#	# aod index
#	http://www.bbc.co.uk/radio/aod/index_noframes.shtml
# 	# schedule feeds
#	http://www.bbc.co.uk/bbcthree/programmes/schedules.xml
#	# These need drill-down to get episodes:
#	# TV schedules by date
#	http://www.bbc.co.uk/iplayer/widget/schedule/service/cbeebies/date/20080704
#	# TV schedules in JSON, Yaml or XML
#	http://www.bbc.co.uk/cbbc/programmes/schedules.(json|yaml|xml)
#	# TV index on programmes tv
#	http://www.bbc.co.uk/tv/programmes/a-z/by/*/player
#	# TV + Radio
#	http://www.bbc.co.uk/programmes/a-z/by/*/player
#	# All TV (limit has effect of limiting to 2.? times number entries kB??)
#	# seems that only around 50% of progs are available here compared to programmes site:
#	http://feeds.bbc.co.uk/iplayer/categories/tv/list/limit/200
#	# All Radio
#	http://feeds.bbc.co.uk/iplayer/categories/radio/list/limit/999
#	# New:
#	# iCal feeds see: http://www.bbc.co.uk/blogs/radiolabs/2008/07/some_ical_views_onto_programme.shtml
#	http://bbc.co.uk/programmes/b0079cmw/episodes/player.ics
#	# Other data
#	http://www.bbc.co.uk/cbbc/programmes/genres/childrens/player
#	http://www.bbc.co.uk/programmes/genres/childrens/schedules/upcoming.ics
#
# get_links( <radio|tv|podcast> )
sub get_links {
	my @cache;
	my $now = time();
	my $type = shift;

	# Open cache file (need to verify we can even read this)
	if ( open(CACHE, "< $cachefile{$type}") ) {
		@cache = <CACHE>;
		close (CACHE);
	}

	# Read cache into %pid_old and %index_pid_old if cache exists
	my %prog_old;
	my %index_pid_old;
	if (@cache) {
		for (@cache) {
			# Populate %prog from cache
			chomp();
			my ($index, $type, $name, $pid, $available, $episode, $versions, $duration, $desc, $channel, $categories, $thumbnail, $timeadded) = split /\|/;
			# Create data structure with prog data
			$prog_old{$pid} = {
				'index'		=> $index,
				'name'		=> $name,
				'episode'	=> $episode,
				'desc'		=> $desc,
				'available'	=> $available,
				'duration'	=> $duration,
				'versions'	=> $versions,
				'channel'	=> $channel,
				'categories'	=> $categories,
				'thumbnail'	=> $thumbnail,
				'type'		=> $type,
				'timeadded'	=> $timeadded,
			};
			$index_pid_old{$index}	= $pid;
		}
	}

	# if a cache file doesn't exist/corrupted, flush option is specified or original file is older than $cache_sec then download new data
	if ( (! @cache) || (! -f $cachefile{$type}) || $opt{flush} || ($now >= ( stat($cachefile{$type})->mtime + $cache_secs )) ) {

		# Podcast only
		get_podcast_links() if $type eq 'podcast';

		# Radio and TV
		get_links_atom( $type, \%{$channels{$type}} ) if $type =~ /(tv|radio)/;

		# Sort indexes
		sort_indexes();
		
		# Open cache file for writing
		unlink $cachefile{$type};
		my $now = time();
		if ( open(CACHE, "> $cachefile{$type}") ) {
			for (sort {$a <=> $b} keys %index_pid) {
				my $pid = $index_pid{$_};
				# Only write entries for correct prog type
				if ($prog{$pid}{type} eq $type) {
					# Merge old and new data to retain timestamps
					# if the entry was in old cache then retain timestamp from old entry
					if ( $prog_old{$pid}{timeadded} ) {
						$prog{$pid}{timeadded} = $prog_old{$pid}{timeadded};
					# Else this is a new entry
					} else {
						$prog{$pid}{timeadded} = $now;
						list_prog_entry( $pid, 'Added: ' );
					}
					# write to cache file
					print CACHE "$_|$prog{$pid}{type}|$prog{$pid}{name}|$pid|$prog{$pid}{available}|$prog{$pid}{episode}|$prog{$pid}{versions}|$prog{$pid}{duration}|$prog{$pid}{desc}|$prog{$pid}{channel}|$prog{$pid}{categories}|$prog{$pid}{thumbnail}|$prog{$pid}{timeadded}\n";
				}
			}
			close (CACHE);
		} else {
			logger "WARNING: Couldn't open cache file '$cachefile{$type}' for writing\n";
		}


	# Else copy data from existing cache file into existing %prog hash
	} else {
		$prog{$_} = $prog_old{$_} for keys %prog_old;
		$index_pid{$_} = $index_pid_old{$_} for keys %index_pid_old;
	}
	return 0;
}



# Usage: download_programme (<pid>)
sub download_programme {
	my $pid = shift;

	# Setup user-agent
	# Switch off automatic redirects
	my $ua = LWP::UserAgent->new( requests_redirectable => [] );
	# Setup user agent
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 1, ignore_discard => 1 ) );

	my $dir = $download_dir{ $prog{$pid}{type} };
	$prog{$pid}{ext} = 'mov';

	# If were a podcast...
	if ( $prog{$pid}{type} eq 'podcast' ) {
		# Determine the correct filename and extension for this download
		my $filename_orig = $pid;
		$prog{$pid}{ext} = $pid;
		$filename_orig =~ s|^.+/(.+?)\.\w+$|$1|g;
		$prog{$pid}{ext} =~ s|^.*\.(\w+)$|$1|g;
		my $file_prefix = generate_download_filename_prefix($pid, $dir, "<longname> - <episode> $filename_orig");
		$prog{$pid}{fileprefix} = $file_prefix;
		$prog{$pid}{dir} = $dir;
		logger "\rINFO: File name prefix = $file_prefix                  \n";
		my $file_done = "${dir}/${file_prefix}.$prog{$pid}{ext}";
		my $file = "${dir}/${file_prefix}.partial.$prog{$pid}{ext}";
		$prog{$pid}{filename} = $file_done;
		if ( -f $file_done ) {
			logger "WARNING: File $file_done already exists\n\n";
			return 1;
		}

		# Skip from here if we are only testing downloads
		return 0 if $opt{test};

		return download_podcast_stream( $ua, $pid, $file, $file_done );
	}

	# Create a full URL from the PID specified
	my $page = $pid_page_url_prefix.$pid;
	logger "INFO: Attempting to Download: $prog{$pid}{name} - $prog{$pid}{episode}\n";

	# Get stage_1 content
	my @content = download_stage_1($ua, $page);
	return 7 if ! @content;

	# Non-UK detection
	# Need to check this again after iplayer2 release
	#print @content;
	#if ( grep /only available to play in the UK/i, @content ) {
	#	logger "\nERROR: This service will only work from the UK or via a UK based web proxy.\n";
	#	exit 3;
	#}

	#embeddedMedia.semp.data = {
	#        pid: "b00dcqnk",
	#        availability: 0,
	#        mode: 1,
	#
	#        title: "The Chris Moyles Show: 17/09/2008",
	#        width: 640,
	#        height: 395,
	#        visualisation : {
	#                metaFile: "http://www.bbc.co.uk/iplayer/playlist/b00dcqnk"
	#        },
	#        flash: {
	#                configFile: "http://www.bbc.co.uk/emp/iplayer/config.xml",
	#                metaFile: "http://www.bbc.co.uk/iplayer/playlist/b00dcqnk"
	#        },
	#        real: {
	#                metaFile: "http://www.bbc.co.uk/iplayer/aod/playlists/pn/nc/d0/0b/RadioBridge_0530_bbc_radio_one.ram"
	#        },
	#        wmp: {
	#                metaFile: ""
	#        }
	#};

	# If we have the following then this is audio
	#real: {
	#	metaFile: "http://www.bbc.co.uk/radio/aod/playlists/gs/5d/c0/0b/0900_bbc_radio_two.ram"	

	# Detect if this content is for radio
	my $usemp3 = 0;
	if ( grep /real:\s*.\s*metaFile:\s*".+?"/, (join ' ', @content) ) {

		# Type is definitely radio
		$prog{$pid}{type} = 'radio';
		$dir = $download_dir{ $prog{$pid}{type} };

		# Do we have an mp3 stream? (check for flash: metafile: "") - unless realaudio option is specified
		if ( $opt{realaudio} ) {
			logger "INFO: RealAudio stream media is available\n" if $opt{verbose};

		# Else check if mp3 stream available
		} else {
			if (  grep /flash:\s+.\s+configFile:\s+".+?",\s+metaFile:\s*"http.+?"/, (join ' ', @content) ) {
				$usemp3 = 1;
				$prog{$pid}{ext} = 'mp3';
				logger "INFO: MP3 stream media is available\n" if $opt{verbose};

			# if mp3audio option is specified do not fallback to realaudio
			} elsif ( $opt{mp3audio} ) {
				logger "ERROR: No MP3 stream media is available - not falling back to RealAudio\n";
				return 1;

			# if not then force realaudio option as fallback
			} else {
				$opt{realaudio} = 1;
				logger "INFO: No MP3 stream media is available - falling back to RealAudio\n" if $opt{verbose};
			}
		}

		# Use realplayer stream
		if ( $opt{realaudio} ) {

			# Check dependancies for radio programme transcoding / streaming
			# Check if we need 'tee'
			if ( (! exists_in_path($tee)) && $opt{stdout} && (! $opt{nowrite}) ) {
				logger "\nERROR: $tee does not exist in path, skipping\n";
				return 20;
			}
			# Check if we have mplayer and lame
			if ( (! $opt{wav}) && (! $opt{raw}) && (! exists_in_path($lame)) ) {
				logger "\nWARNING: Required $lame does not exist, falling back to wav mode\n";
				$opt{wav} = 1;
			}		
			if (! exists_in_path($mplayer)) {
				logger "\nERROR: Required $mplayer does not exist, skipping\n";
				return 20;
			}

			# Extract Long Name, e.g.: title: "Jonathan Ross: 05/07/2008",
			chomp( my $title = ( grep /title:\s+/, @content)[0] );
			$title =~ s/^\s*title:\s\"\s*(.+)\s*\".*$/$1/g;
			# Strip off the episode name
			$title =~ m{^(.+):\s*(.*?)$};
			$prog{$pid}{longname} = $1;
			$prog{$pid}{episode} = $2;

			# Get version => pid
			my %version_pids = get_version_pids( @content );
			my $url_2;
	
			logger "\nINFO: Checking existence of programme\n";
			$prog{$pid}{version} = 'Original';
			# Create url with appended 6 digit random number
			my $url_1 = ${audio_download_prefix}.'/'.$version_pids{Original};
		
			logger "INFO: Version = $prog{$pid}{version}\n" if $opt{verbose};
			logger "INFO: Stage 2 URL = $url_1\n" if $opt{verbose};

			# Get these web bugs to whitelist our cookie if we don't have one already
			if ( get_web_bugs($ua, @content) ) {
				logger "ERROR: Could not whitelist cookie\n";
				return 'retry';
			} 

			$url_2 = get_audio_stream_download_url( $ua, $url_1 );

			# Report error if no versions are available
			if ( ! $url_2 ) {
				logger "ERROR: No Stage 2 URL\n" if $opt{verbose};
				return 15;
			}

			# Determine the correct filenames for this download
			$prog{$pid}{ext} = 'mp3';
			$prog{$pid}{ext} = 'ra'  if $opt{raw};
			$prog{$pid}{ext} = 'wav' if $opt{wav};
			my $file_prefix = generate_download_filename_prefix( $pid, ${dir}, "<longname> - <episode> <pid>" );
			logger "\rINFO: File name prefix = $file_prefix                 \n";
			$prog{$pid}{fileprefix} = $file_prefix;
			$prog{$pid}{dir} = $dir;
			my $file_done = "${dir}/${file_prefix}.$prog{$pid}{ext}";
			my $file = "${dir}/${file_prefix}.partial.$prog{$pid}{ext}";
			$prog{$pid}{filename} = $file_done;
			if ( -f $file_done ) {
				logger "WARNING: File $file_done already exists\n\n";
				return 1;
			}

			# Display RTMP stream data if required
			get_media_stream_data( $pid, $version_pids{ $prog{$pid}{version} }, 'all' ) if $opt{streaminfo};

			# Skip from here if we are only testing downloads
			return 0 if $opt{test};

			# Do the audio download
			return download_rtsp_stream( $ua, $url_2, $file, $file_done, $pid );
		}

	} else {
		# Type is definitely tv
		$prog{$pid}{type} = 'tv';
		$dir = $download_dir{ $prog{$pid}{type} };
	}


	# iPhone mp3/h.264 stream downloading...

	# Check if we have vlc - if not use iPhone mode
	if ( $opt{n96} && (! exists_in_path($vlc)) ) {
		logger "\nWARNING: Required $vlc does not exist, falling back to iPhone mode\n";
		$opt{n96} = 0;
	}		

	# Parse if programme available
	#    iplayer_streaming_http_mp4 : [
	#    ],  ### This part is empty == no mov version yet
	if ( grep /iplayer_streaming_http_mp4 : \[\s+\],/i, @content ) {
		logger "\rWARNING: Programme is reported as not yet ready for download\n";
		# Will return from here once satisfied that this test is reliable
		#return 11;
	} else {
		logger "\rINFO: Programme is reported as ready for download\n";
	}

	# Extract Long Name, e.g.: iplayer.episode.setTitle("DIY SOS: Series 16: Swansea");
	chomp( $prog{$pid}{longname} = ( grep /iplayer\.episode\.setTitle/, @content)[0] );
	$prog{$pid}{longname} =~ s/^\s*iplayer\.episode\.setTitle\(\"\s*(.+)\s*\".*$/$1/g;
	# Strip off the episode name
	$prog{$pid}{longname} =~ s/^(.+):.*?$/$1/g;

	# Get type => verpid
	my %version_pids = get_version_pids( @content );
	my $url_2;
	my $got_url;
	
	# Do this for each version tried in this order (if they appaered in the content)
	for my $version ( qw/ Original Signed AudioDescribed OpenSubtitled Shortened Lengthened Other / ) {

		# Change $verpid to 'Original' type if it exists, then Used 'Signed' otherwise
		if ( grep /^$version$/, keys %version_pids ) {
			logger "INFO: Checking existence of $version version\n";
			$prog{$pid}{version} = $version;
			logger "INFO: Version = $prog{$pid}{version}\n" if $opt{verbose};

			# Get these web bugs to whitelist our cookie if we don't have one already
			if ( get_web_bugs($ua, @content) ) {
				logger "ERROR: Could not whitelist cookie\n";
				return 16;
			} 
			$url_2 = get_iphone_stream_download_url( $ua, $version_pids{$version} );
			$got_url = 1;
		}
		# Break out of loop if we have an actual URL
		last if $got_url && $url_2;
	}

	# Report error if no versions are available
	if ( ! $got_url ) {
		logger "ERROR: No versions exist for download\n";
		return 14;
	}
	# Report error if failed to get URL for version
	if ( $got_url && ! $url_2 ) {
		logger "ERROR: No Stage 2 URL\n" if $opt{verbose};
		# If mp3 audio stream does not exist force realaudio mode and retry
		if ( $usemp3 && ! $opt{mp3audio}) {
			$opt{realaudio} = 1;
			return 'retry';
		}
		return 15;
	}
	
	# Display media stream data if required
	get_media_stream_data( $pid, $version_pids{ $prog{$pid}{version} }, 'all' ) if $opt{streaminfo};

	# Determine the correct filenames for this download
	my $file_prefix = generate_download_filename_prefix( $pid, $dir );
	logger "\rINFO: File name prefix = $file_prefix                 \n";
	$prog{$pid}{fileprefix} = $file_prefix;
	$prog{$pid}{dir} = $dir;
	my $file_done = "${dir}/${file_prefix}.$prog{$pid}{ext}";
	my $file = "${dir}/${file_prefix}.partial.$prog{$pid}{ext}";
	$prog{$pid}{filename} = $file_done;
	if ( -f $file_done ) {
		logger "WARNING: File $file_done already exists\n\n";
		return 1;
	}

	# Skip from here if we are only testing downloads
	return 0 if $opt{test};

	# Get subtitles if they exist and are required
	my $subfile_done;
	my $subfile;
	if ( $opt{subtitles} ) {
		$subfile_done = "${dir}/${file_prefix}.srt";
		$subfile = "${dir}/${file_prefix}.partial.srt";
		download_subtitles( $ua, $subfile, $version_pids{ $prog{$pid}{version} } );
	}

	# Do the N96 h.264 download
	my $return;
	if ( $opt{n96} ) {
		my $url = get_media_stream_data( $pid, $version_pids{ $prog{$pid}{version} }, 'n96' );
		$return = download_h264_low_stream( $ua, $url, $file, $file_done );

	# Do the iPhone h.264 download
	} elsif ( $prog{$pid}{type} eq 'tv' ) {
		$return = download_iphone_stream( $ua, $url_2, $file, $file_done, 1 );

	# Do the iPhone mp3 download
	} elsif ( $prog{$pid}{type} eq 'radio' ) {
		$return = download_iphone_stream( $ua, $url_2, $file, $file_done, 0 );
		# If the iphone mp3 download fails then it's probably not ready yet so retry using realaudio
		$opt{realaudio} = 1 if $return eq 'retry';
	}
	
	# Rename the subtitle file accordingly
	move($subfile, $subfile_done) if $opt{subtitles} && -f $subfile;

	return $return;
}



# Download Subtitles
#GET http://www.bbc.co.uk/mediaselector/4/mtis/stream/b008dc8r
#<?xml version="1.0" encoding="UTF-8"?>                                     
#<mediaSelection xmlns="http://bbc.co.uk/2008/mp/mediaselection">           
#<media kind="captions"                                                     
#        type="application/ttaf+xml"   >                                    
#        <connection                                                        
#                priority="10"                                              
#                kind="http"                                                
#                server="http://www.bbc.co.uk/iplayer/subtitles/"           
#                identifier="b0008dc8rstreaming89808204.xml"                
#                href="http://www.bbc.co.uk/iplayer/subtitles/b0008dc8rstreaming89808204.xml" 
#        />                                                                                   
#</media>                                                                                     
#....
sub download_subtitles {
	my ( $ua, $file, $verpid ) = @_;
	my $suburl;
	my $subs;
	logger "INFO: Getting Subtitle metadata for $verpid\n" if $opt{verbose};
	my $xml = request_url_retry($ua, 'http://www.bbc.co.uk/mediaselector/4/mtis/stream/'.$verpid, 3, '', '');

	# flatten
	$xml =~ s/\n/ /g;

	# Extract url
	$suburl = $1 if $xml =~ m{<media\s+kind="captions".+?href="(.+?)".+?</media>};

	# Return if we have no url
	if (! $suburl) {
		logger "INFO: Subtitles not available\n";
		return 2;
	}

	logger "INFO: Getting Subtitles from $suburl\n" if $opt{verbose};

	# Open subs file
	unlink($file);
	my $fh = open_file_append($file);

	# Download subs
	$subs = request_url_retry($ua, $suburl, 2);
	if (! $subs ) {
		logger "ERROR: Subtitle Download failed\n";
		return 1;
	} else {
		logger "INFO: Downloaded Subtitles\n";
	}

	# Convert the format to srt
	# SRT:
	#1
	#00:01:22,490 --> 00:01:26,494
	#Next round!
	#
	#2
	#00:01:33,710 --> 00:01:37,714
	#Now that we've moved to paradise, there's nothing to eat.
	#
	
	# TT:
	#<p begin="0:01:12.400" end="0:01:13.880">Thinking.</p>

	my $count = 1;
	my @lines = grep /<p\s+begin/, split /\n/, $subs;
	for ( @lines ) {
		my ( $begin, $end, $sub );
		$begin = $1 if m{begin="(.+?)"};
		$end =   $1 if m{end="(.+?)"};
		$sub =	 $1 if m{>(.+?)</p>};
		if ($begin && $end && $sub ) {
			$begin =~ s/\./,/g;
			$end =~ s/\./,/g;
			if ($opt{suboffset}) {
				$begin = subtitle_offset( $begin, $opt{suboffset} );
				$end = subtitle_offset( $end, $opt{suboffset} );
			}
			decode_entities($sub);
			# Write to file
			print $fh "$count\n";
			print $fh "$begin --> $end\n";
			print $fh "$sub\n\n";
			$count++;
		}
	}	
	close $fh;

	return 0;
}



# Returns an offset timestamp given an srt begin or end timestamp and offset in ms
sub subtitle_offset {
	my ( $timestamp, $offset ) = @_;
	my ( $hr, $min, $sec, $ms ) = split /[:,\.]/, $timestamp;
	# split into hrs, mins, secs, ms
	my $ts = $ms + $sec*1000 + $min*60*1000 + $hr*60*60*1000 + $offset;
	$hr = int( $ts/(60*60*1000) );
	$ts -= $hr*60*60*1000;
	$min = int( $ts/(60*1000) );
	$ts -= $min*60*1000;
	$sec = int( $ts/1000 );
	$ts -= $sec*1000;
	$ms = $ts;
	return "$hr:$min:$sec,$ms";
}



# Gets media streams data for this version pid
# $media = all|flashhigh|flashnormal|iphone|flashwii|flashaudio|realaudio|subtitles
sub get_media_stream_data {
	my ( $pid, $verpid, $media ) = @_;
	my $url;
	my $ua = LWP::UserAgent->new();
	# Setup user agent with redirection enabled
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 1, ignore_discard => 1 ) );
	$opt{quiet} = 0 if $opt{streaminfo};
	logger "INFO: Getting media stream metadata for $prog{$pid}{name} - $prog{$pid}{episode}, $verpid\n";
	my $xml = request_url_retry($ua, 'http://www.bbc.co.uk/mediaselector/4/mtis/stream/'.$verpid, 3, '', '');
	logger "\n$xml\n" if $opt{debug};
	# flatten
	$xml =~ s/\n/ /g;

	my ($server, $authstring, $identifier, $href);

	# h.264 high quality stream
	#	<media kind="video"
	#        width="640"
	#        height="360"
	#        type="video/mp4"
	#        encoding="h264"  >
	#        <connection
	#                priority="10"
	#                application="bbciplayertok"
	#                kind="level3"
	#                server="bbciplayertokfs.fplive.net"
	#                identifier="mp4:b000zxf4-H26490898078"
	#                authString="d52f77fede048f1ffd6587fd47446dee"
	#        />
	if ( $media =~ /^(flashhigh|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/mp4".+?encoding="h264".+?kind="level3"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		logger "INFO: RTMP h.264 high quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP high quality stream URL: $url\n";
	}

	# h.264 normal quality stream
	#	<media kind="video"
	#        width="512"
	#        height="288"
	#        type="video/x-flv"
	#        encoding="vp6"  >
	#        <connection
	#                priority="10"
	#                kind="akamai"
	#                server="cp41752.edgefcs.net"
	#                identifier="secure/b000zxf4-streaming90898078"
	#                authString="daEdSdgbcaibFa7biaobCaYdadyaTamazbq-biXsum-cCp-FqrECnEoGBwFvwG"
	#        />
	#	</media>
	#
	if ( $media =~ /^(flashnormal|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/x-flv".+?encoding="vp6".+?kind="akamai"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		logger "INFO: RTMP h.264 normal quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP normal quality stream URL: $url\n";
	}

	# Wii h.264 standard quality stream
	#<media kind="video"
	#        width="512"
	#        height="288"
	#        type="video/x-flv"
	#        encoding="spark"  >
	#        <connection
	#                priority="10"
	#                kind="akamai"
	#                server="cp41752.edgefcs.net"
	#                identifier="secure/5242138581547639062"
	#                authString="daEd8dLbGaPaZdzdNcwd.auaydJcxcHandp-biX5YL-cCp-BqsECnxnGEsHwyE"
	#        />
	#</media>
	if ( $media =~ /^(flashwii|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/x-flv".+?encoding="spark".+?kind="akamai"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		logger "INFO: RTMP Wii normal quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP Wii normal quality stream URL: $url\n";
	}

	# iPhone h.264/mp3 stream
	#<media kind="video"
	#        width="480"
	#        height="272"
	#        type="video/mp4"
	#        encoding="h264"  >
	#        <connection
	#                priority="10"
	#                kind="sis"
	#                server="http://www.bbc.co.uk/mediaselector/3/auth/stream/"
	#                identifier="5242138581547639062"
	#                href="http://www.bbc.co.uk/mediaselector/3/auth/stream/5242138581547639062.mp4"
	#        />
	#</media>
	if ( $media =~ /^(iphone|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/mp4".+?encoding="h264".+?kind="sis"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		logger "INFO: iPhone stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$href";
		logger "INFO: iPhone stream URL: $url\n";
	}

	# Nokia N96 h.264 low quality stream
	#<media kind="video"
	#        type="video/mpeg"
	#        encoding="h264"  >
	#        <connection
	#                priority="10"
	#                kind="sis"
	#                server="http://www.bbc.co.uk/mediaselector/4/sdp/"
	#                identifier="b00108ld/iplayer_streaming_n95_wifi"
	#                href="http://www.bbc.co.uk/mediaselector/4/sdp/b00108ld/iplayer_streaming_n95_wifi"
	#        />
	#</media>
	if ( $media =~ /^(n96|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/mpeg".+?encoding="h264".+?kind="sis"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		$opt{quiet} = 1 if $opt{streaminfo};
		chomp( my $rtsp = download_block(undef, $href, $ua, 0, undef) );
		$opt{quiet} = 0 if $opt{streaminfo};
		logger "INFO: Nokia N96 h.264 low quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$rtsp";
		logger "INFO: Nokia N96 h.264 low quality stream URL: $url\n";
	}

	# Audio rtmp mp3
	#<media kind="audio"
	#        type="audio/mpeg"
	#        encoding="mp3"  >
	#        <connection
	#                priority="10"
	#                kind="akamai"
	#                server="cp48181.edgefcs.net"
	#                identifier="mp3:secure/radio1/RBN2_mashup_b00d67h9_2008_09_05_22_14_25"
	#                authString="daEbQa1c6cda6aHdudxagcCcUcVbvbncmdK-biXtzq-cCp-DnoFIpznNBqHnzF"
	#        />
	#</media>
	if ( $media =~ /^(flashaudio|all)$/ && $xml =~ m{<media\s+kind="audio".+?type="audio/mpeg".+?encoding="mp3".+?kind="akamai"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		# Remove offending mp3: at the start of the identifier
		$identifier =~ s/^mp3://;
		logger "INFO: RTMP MP3 stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP stream URL: $url\n";
	}

	# ReadAudio stream
	#<media kind="audio"
	#       type="audio/real"
	#        encoding="real"  >
	#        <connection
	#                priority="10"
	#                kind="sis"
	#                server="http://www.bbc.co.uk"
	#                identifier="/radio/aod/playlists/9h/76/d0/0b/2000_bbc_radio_one"
	#                href="http://www.bbc.co.uk/radio/aod/playlists/9h/76/d0/0b/2000_bbc_radio_one.ram"
	#        />
	#</media>
	if ( $media =~ /^(realaudio|all)$/ && $xml =~ m{<media\s+kind="audio".+?type="audio/real".+?encoding="real".+?kind="sis"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		$opt{quiet} = 1 if $opt{streaminfo};
		chomp( my $rtsp = download_block(undef, $href, $ua, 0, undef) );
		$opt{quiet} = 0 if $opt{streaminfo};
		logger "INFO: RealAudio RTSP stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$rtsp";
		logger "INFO: RealAudio RTSP stream URL: $url\n";
	}

	# Subtitles stream
	#<media kind="captions"
	#        type="application/ttaf+xml"   >
	#        <connection
	#                priority="10"
	#                kind="http"
	#                server="http://www.bbc.co.uk/iplayer/subtitles/"
	#                identifier="b0008dc8rstreaming89808204.xml"
	#                href="http://www.bbc.co.uk/iplayer/subtitles/b0008dc8rstreaming89808204.xml"
	#        />
	#</media>
	if ( $media =~ /^(subtitles|all)$/ && $xml =~ m{<media\s+kind="captions".+?type="application/ttaf\+xml".+?kind="http"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		logger "INFO: Subtitles stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$href";
		logger "INFO: Subtitles stream URL: $url\n";
	}

	logger "\n" if $opt{streaminfo};
	$opt{quiet} = 1 if $opt{streaminfo};
	return $url if ! $opt{streaminfo};
}



# Get stage 1 content
sub download_stage_1 {
	my ( $ua, $page ) = @_;

	logger "INFO: Stage 1 URL = $page\n" if $opt{verbose};
	logger "\rGetting iplayer programme page        " if ! $opt{verbose};

	# Stage 1: get PID and set cookie
	# This page Doesn't work with safari ua anymore....
	# If this break in future, use http://www.bbc.co.uk/mediaselector/4/json/stream/<pid> However this
	#   method does not provide anything except the next URL, cannot get other prog info from it
	$ua->agent( );
	# send request
	my $res = $ua->request( HTTP::Request->new( GET => $page ) );
	if ( ! $res->is_success ) {
		logger "\rERROR: Failed to get programme ID from iplayer site\n\n";
		return '';
	}
	return split /\n/, $res->content;
}



# Actually do the h.264/mp3 downloading
# ( $ua, $url_2, $file, $file_done, '0|1 == rearrange moov' )
sub download_iphone_stream {
	my ( $ua, $url_2, $file, $file_done, $rearrange ) = @_;

	# Stage 3a: Download 1st byte to get exact file length
	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};

	# Setup request header
	my $h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{coremedia},
		'Accept'	=> '*/*',
		'Range'		=> 'bytes=0-1',
	);
	my $req = HTTP::Request->new ('GET', $url_2, $h);
	my $res = $ua->request($req);
	# e.g. Content-Range: bytes 0-1/181338136
	my $file_len = $res->header("Content-Range");
	$file_len =~ s|^bytes 0-1/(\d+).*$|$1|;
	logger "INFO: Download File Length $file_len\n" if $opt{verbose};

	# Only do this if we're rearranging QT streams
	my $mdat_start = 0;
	my $moov_start = $file_len + 1;
	my $header;
	if ($rearrange) {
		# Get ftyp+wide header etc
		$mdat_start = 0x1c;
		my $buffer = download_block(undef, $url_2, $ua, 0, $mdat_start + 4);
		# Get bytes upto (but not including) mdat atom start -> $header
		$header = download_block(undef, $url_2, $ua, 0, $mdat_start - 1, $file_len);

		# Detemine moov start
		# Get mdat_end_offset_chars from downloaded block
		my $mdat_end_offset_chars = substr($buffer, $mdat_start, 4);
		my $mdat_end_offset = bytestring_to_int($mdat_end_offset_chars);
		logger "mdat_end_offset = ".get_hex($mdat_end_offset_chars)." = $mdat_end_offset\n" if $opt{verbose};
		logger "mdat_end_offset (decimal) = $mdat_end_offset\n" if $opt{verbose};
		# The MOOV box starts one byte after MDAT box ends
		$moov_start = $mdat_start + $mdat_end_offset;


		## scan 2nd level atoms in moov atom until we get stco atom(s)
		# We can skip first 8 bytes (moov atom header)
		#my $i = 8;
		#while( $i < $moov_length - 4 ) {
		#  my $atom_len = bytestring_to_int( substr($moovdata, $i, 4) );
		#  my $atom_name = substr($moovdata, $i+4, 4);
		#  logger "Parsing atom: $atom_name, length: $atom_len\n";
		#  # Increment $i by atom_len to get next atom
		#  $i += $atom_len;
		#}
	}

	# If we have partial content and wish to stream, resume the download & spawn off STDOUT from existing file start 
	# Sanity check - we cannot support downloading of partial content if we're streaming also. 
	if ( $opt{stdout} && (! $opt{nowrite}) && -f $file ) {
		logger "WARNING: Partially downloaded file exists, streaming will start from the beginning of the programme\n";
		# Don't do usual streaming code
		$opt{stdout} = 0;
		$childpid = fork();
		if (! $childpid) {
			# Child starts here
			logger "INFO: Streaming directly for partially downloaded file $file\n";
			if ( ! open( STREAMIN, "< $file" ) ) {
				logger "INFO: Cannot Read partially downloaded file to stream\n";
				exit 4;
			}
			my $outbuf;
			# Write out until we run out of bytes
			my $bytes_read = 65536;
			while ( $bytes_read == 65536 ) {
				$bytes_read = read(STREAMIN, $outbuf, 65536 );
				#logger "INFO: Read $bytes_read bytes\n";
				print STDOUT $outbuf;
			}
			close STREAMIN;
			logger "INFO: Stream thread has completed\n";
			exit 0;
		}
	}

	# Open file if required
	my $fh = open_file_append($file);

	# If the partial file already exists, then resume from the correct mdat/download offset
	my $restart_offset = $mdat_start;
	my $moovdata;
	my $moov_length = 0;

	if ($rearrange) {
		# if cookie fails then trigger a retry after deleting cookiejar
		# Determine moov atom length so we can work out if the partially downloaded file has the moov atom in it already
		$moov_length = bytestring_to_int( download_block( undef, $url_2, $ua, $moov_start, $moov_start+3 ) );
		logger "INFO: moov atom length = $moov_length                          \n" if $opt{verbose};
		# Sanity check this moov length - chances are that were being served up a duff file if this is > 10% of the file size or < 64k
		if ( $moov_length > (${moov_start}/9.0) || $moov_length < 65536 ) {
			logger "WARNING: Bad file download, deleting cookie                 \n";
			$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 0, ignore_discard => 0 ) );
			unlink $cookiejar;
			unlink $file;
			return 'retry';
		}
	}

	# If we have a too-small-sized file and not stdout and not no-write then this is a partial download
	if (-f $file && (! $opt{stdout}) && (! $opt{nowrite}) && stat($file)->size > ($moov_length+$mdat_start) ) {
		# Calculate new start offset (considering that we've put moov first in file)
		$restart_offset = stat($file)->size - $moov_length;
		logger "INFO: Resuming download from $restart_offset                        \n";
	}

	if ($rearrange) {
		# If we have no existing file, a file which doesn't yet even have the moov atom, or using stdout (or no-write option)
		if ( $opt{stdout} || $opt{nowrite} || stat($file)->size < ($moov_length+$mdat_start) ) {
			# get moov chunk into memory
			$moovdata = download_block( undef, $url_2, $ua, $moov_start, (${file_len}-1) );
			# Process the moov data so that we can relocate it (change the chunk offsets that are absolute)
			$moov_length = relocate_moov_chunk_offsets( $moovdata );
			# write moov atom to file next (yes - were rearranging the file - moov+header+mdat - not header+mdat+moov)
			logger "INFO: Appending moov+ftype+wide atoms to $file\n" if $opt{verbose};
			# Write moov atom
			print $fh $moovdata if ! $opt{nowrite};
			print STDOUT $moovdata if $opt{stdout};
			# Write header atoms (ftyp, wide)
			print $fh $header if ! $opt{nowrite};
			print STDOUT $header if $opt{stdout};
		}
	}

	# Create symlink for freevo if required
	if ( $opt{symlink} ) {
		# remove old symlink
		unlink $opt{symlink} if -l $opt{symlink};
		symlink $file, $opt{symlink};
	}

	# Start marker
	my $start_time = time();

	# Download mdat in 16MB blocks
	my $chunk_size = 0x1000000;
	for ( my $s = $restart_offset; $s < ${moov_start}-1; $s+= $chunk_size ) {
		# get mdat chunk into file
		my $retcode;
		my $e;
		# Get block end offset
		if ( ($s + $chunk_size - 1) > (${moov_start}-1) ) {
			$e = $moov_start - 1;
		} else {
			$e = $s + $chunk_size - 1;
		}
		# Get block from URL and append to $file
		if ( download_block($file, $url_2, $ua, $s, $e, $file_len, $fh ) ) {
			logger "ERROR: Could not download block $s - $e from $file\n\n";
			return 9;
		}
	}

	# end marker
	my $end_time = time();

	# Should now be able to concatenate header.block + mdat.block + moov.block to get movie!
	# Calculate average speed, duration and total bytes downloaded
	logger sprintf("INFO: Downloaded %.2fMB in %s at %5.0fkbps to %s\n", 
		($moov_start - 1 - $restart_offset) / (1024.0 * 1024.0),
		sprintf("%02d:%02d:%02d", ( gmtime($end_time - $start_time))[2,1,0] ), 
		( $moov_start - 1 - $restart_offset ) / ($end_time - $start_time) / 1024.0 * 8.0, 
		$file_done );

	# Moving file into place as complete (if not stdout)
	move($file, $file_done) if ! $opt{stdout};
	return 0;
}



# Actually do the N96 h.264 downloading
sub download_h264_low_stream {
	my ( $ua, $url_2, $file, $file_done ) = @_;

	# Change filename extension
	$file =~ s/mov$/mpg/gi;
	$file_done =~ s/mov$/mpg/gi;

	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};
	if ( ! $opt{stdout} ) {
		logger "INFO: Downloading Low Quality H.264 stream\n";
		my $cmd = "$vlc $vlc_opts --sout file/ts:${file} $url_2 1>&2";
		if ( system($cmd) ) {
			return 2;
		}

	# to STDOUT
	} else {
		logger "INFO: Streaming Low Quality H.264 stream to stdout\n";
		my $cmd = "$vlc $vlc_opts --sout file/ts:- $url_2 1>&2";
		if ( system($cmd) ) {
			return 2;
		}	
	}
	logger "INFO: Downloaded $file_done\n";
	# Moving file into place as complete (if not stdout)
	move($file, $file_done) if ! $opt{stdout};
	return 0;
}



# Actually do the rtsp downloading
sub download_rtsp_stream {
	my ( $ua, $url_2, $file, $file_done, $pid ) = @_;
	my $childpid;

	# Create named pipe
	if ( $^O !~ /^MSWin32$/ ) {
		mkfifo($namedpipe, 0700) if (! $opt{wav}) && (! $opt{raw});
	} else {
		logger "WARNING: fifos/named pipes are not supported\n" if $opt{verbose};
	}
	
	# Stage 3a: Download 1st byte to get exact file length
	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};

	# Determine offset for resuming download
	my $h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{coremedia},
		'Accept'	=> '*/*',
		'Range'		=> 'bytes=0-',
	);
	my $req = HTTP::Request->new ('GET', $url_2, $h);
	my $res = $ua->request($req);
	chomp( my $rtsp = $res->content );
	# String trailing/leading whitespace and newlines
	$rtsp =~ s/(^\s+|\s+$|\n)//g;
	logger "INFO: Stage 4 URL = $rtsp\n" if $opt{verbose};

	# Create ID3 tagging options for lame (escape " for shell)
	my ( $id3_name, $id3_episode, $id3_desc, $id3_channel ) = ( $prog{$pid}{name}, $prog{$pid}{episode}, $prog{$pid}{desc}, $prog{$pid}{channel} );
	$id3_name =~ s|"|\"|g for ($id3_name, $id3_episode, $id3_desc, $id3_channel);
	$lame_opts .= "--ignore-tag-errors --ty ".( (localtime())[5] + 1900 )." --tl \"$id3_name\" --tt \"$id3_episode\" --ta \"$id3_channel\" --tc \"$id3_desc\" ";

	# Use post-download transcoding using lame if namedpipes are not supported (i.e. ActivePerl/Windows)
	# (Fallback if no namedpipe support and raw/wav not specified)
	if ( (! -p $namedpipe) && ! ( $opt{raw} || $opt{wav} ) ) {
		my $cmd;
		# Remove filename extension
		$file =~ s/\.mp3$//gi;
		# Remove named pipe
		unlink $namedpipe;
		logger "INFO: Downloading wav format (followed by transcoding)\n";
		$cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -vc null -vo null -ao pcm:waveheader:fast:file=\"${file}.wav\" \"$rtsp\" 1>&2";
		if ( system($cmd) ) {
			return 2;
		}
		# Transcode
		logger "INFO: Transcoding ${file}.wav\n";
		$cmd = "$lame $lame_opts \"${file}.wav\" \"${file}.mp3\" 1>&2";
		logger "DEGUG: Running $cmd\n" if $opt{debug};
		if ( system($cmd) ) {
			return 2;
		}
		unlink "${file}.wav";
		move "${file}.mp3", $file_done;
		$prog{$pid}{ext} = 'mp3';

	# Fork a child to do transcoding on the fly using a named pipe written to by mplayer
	# else do direct mplayer write to wav file if:
	#  1) we don't have a named pipe available (e.g. in activeperl)
	#  2) --wav was specified to write file only
	} elsif ( $opt{wav} && ! $opt{stdout} ) {
		logger "INFO: Writing wav format\n";
		# Start the mplayer process and write to wav file
		my $cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -vc null -vo null -ao pcm:waveheader:fast:file=\"$file\" \"$rtsp\" 1>&2";
		logger "DEGUG: Running $cmd\n" if $opt{debug};
		if ( system($cmd) ) {
			return 2;
		}
		# Move file to done state
		move $file, $file_done if ! $opt{nowrite};

	# No transcoding if --raw was specified
	} elsif ( $opt{raw} && ! $opt{stdout} ) {
		# Write out to .ra ext instead (used on fallback if no fifo support)
		logger "INFO: Writing raw realaudio stream\n";
		# Start the mplayer process and write to raw file
		my $cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -dumpstream -dumpfile \"$file\" \"$rtsp\" 1>&2";
		logger "DEGUG: Running $cmd\n" if $opt{debug};
		if ( system($cmd) ) {
			return 2;
		}
		# Move file to done state
		move $file, $file_done if ! $opt{nowrite};

	# Use transcoding via named pipes
	} else {
		$childpid = fork();
		if (! $childpid) {
			# Child starts here
			$| = 1;
			logger "INFO: Transcoding $file\n";

			# Stream mp3 to file and stdout simultaneously
			if ( $opt{stdout} && ! $opt{nowrite} ) {
				if ( $opt{wav} || $opt{raw} ) {
					# Race condition - closes named pipe immediately unless we wait
					sleep 5;
					tee($namedpipe, $file);
					#system( "cat $namedpipe 2>/dev/null| $tee $file");
				} else {
					my $cmd = "$lame $lame_opts $namedpipe - 2>/dev/null| $tee \"$file\"";
					logger "DEGUG: Running $cmd\n" if $opt{debug};
					system($cmd);
				}

			# Stream mp3 stdout only
			} elsif ( $opt{stdout} && $opt{nowrite} ) {
				if ( $opt{wav} || $opt{raw} ) {
					sleep 5;
					tee($namedpipe);
					#system( "cat $namedpipe 2>/dev/null");
				} else {
					my $cmd = "$lame $lame_opts $namedpipe - 2>/dev/null";
					logger "DEGUG: Running $cmd\n" if $opt{debug};
					system( "$lame $lame_opts $namedpipe - 2>/dev/null");
				}

			# Stream mp3 to file directly
			} elsif ( ! $opt{stdout} ) {
				my $cmd = "$lame $lame_opts $namedpipe \"$file\" >/dev/null 2>/dev/null";
				logger "DEGUG: Running $cmd\n" if $opt{debug};
				system($cmd);
			}
			# Remove named pipe
			unlink $namedpipe;

			# Move file to done state
			move $file, $file_done if ! $opt{nowrite};
			logger "INFO: Transcoding thread has completed\n";
			exit 0;
		}
		# Start the mplayer process and write to named pipe
		# Raw mode
		if ( $opt{raw} ) {
			my $cmd = "$mplayer $mplayer_opts -cache 32 -bandwidth $bandwidth -dumpstream -dumpfile $namedpipe \"$rtsp\" 1>&2";
			logger "DEGUG: Running $cmd\n" if $opt{debug};
			if ( system($cmd) ) {
				# If we fail then kill off child processes
				kill 9, $childpid;
				return 2;
			}
		# WAV / mp3 mode
		} else {
			my $cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -vc null -vo null -ao pcm:waveheader:fast:file=$namedpipe \"$rtsp\" 1>&2";
			if ( system($cmd) ) {
				# If we fail then kill off child processes
				kill 9, $childpid;
				return 2;
			}
		}
		# Wait for child processes to prevent zombies
		wait;
	}
	logger "INFO: Downloaded $file_done\n";

	return 0;
}



# Actually do the podcast downloading
sub download_podcast_stream {
	my ( $ua, $url_2, $file, $file_done ) = @_;
	my $start_time = time();

	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};

	# Resume partial download?
	my $start = 0;
	if ( -f $file ) {
		$start = stat($file)->size;
		logger "INFO: Resuming download from $start\n";
	}

	my $fh = open_file_append($file);

	if ( download_block($file, $url_2, $ua, $start, undef, undef, $fh) != 0 ) {
		logger "ERROR: Download failed\n";
		return 22;
	} else {

		# end marker
		my $end_time = time();
		# Final file size
		my $size = stat($file)->size;
		# Calculate average speed, duration and total bytes downloaded
		logger sprintf("INFO: Downloaded %.2fMB in %s at %5.0fkbps to %s\n", 
			($size - $start) / (1024.0 * 1024.0),
			sprintf("%02d:%02d:%02d", ( gmtime($end_time - $start_time))[2,1,0] ), 
			( $size - $start ) / ($end_time - $start_time) / 1024.0 * 8.0, 
			$file_done );
		move $file, $file_done;
	}
	return 0;
}



# Get streaming video URL
sub get_iphone_stream_download_url {
		my $ua = shift;
		my $pid = shift;

		# Create url with appended 6 digit random number
		my $url_1 = ${video_download_prefix}.'/'.${pid}.'?'.(sprintf "%06.0f", 1000000*rand(0)).'%20';
		logger "INFO: media stream download URL = $url_1\n" if $opt{verbose};
		
		# Stage 2: e.g. "Location: http://download.iplayer.bbc.co.uk/iplayer_streaming_http_mp4/121285241910131406.mp4?token=iVXexp1yQt4jalB2Hkl%2BMqI25nz2WKiSsqD7LzRmowrwXGe%2Bq94k8KPsm7pI8kDkLslodvHySUyU%0ApM76%2BxEGtoQTF20ZdFjuqo1%2B3b7Qmb2StOGniozptrHEVQl%2FYebFKVNINg%3D%3D%0A"
		logger "\rGetting iplayer download URL         " if ! $opt{verbose};
		my $h = new HTTP::Headers(
			'User-Agent'	=> $user_agent{coremedia},
			'Accept'	=> '*/*',
			'Range'		=> 'bytes=0-1',
		);
		my $req = HTTP::Request->new ('GET', $url_1, $h);
		# send request
		my $res = $ua->request($req);
		# Get resulting Location header (i.e. redirect URL)
		my $url_2 = $res->header("location");
		if ( ! $res->is_redirect ) {
			logger "ERROR: Failed to get redirect from iplayer site\n\n";
			return '';
		}
		# Extract redirection Location URL
		$url_2 =~ s/^Location: (.*)$/$1/g;
		# If we get a Redirection containing statuscode=404 then this prog is not yet ready
		if ( $url_2 =~ /statuscode=404/ ) {
			logger "\rERROR: Programme is not yet ready for download\n";
			return '';
		}

		return $url_2;
}



# Get streaming audio URL (Real => rtsp)
#<media kind="audio"
#        type="audio/real"
#        encoding="real"  >
#        <connection
#                priority="10"
#                kind="sis"
#                server="http://www.bbc.co.uk"
#                identifier="/radio/aod/playlists/gs/5d/c0/0b/0900_bbc_radio_two"
#                href="http://www.bbc.co.uk/radio/aod/playlists/gs/5d/c0/0b/0900_bbc_radio_two.ram"
#        />
#</media>
# OR
#<media kind=""
#        type="audio/real"
#        encoding="real"  >
#        <connection
#                priority="10"
#                kind="edgesuite"
#                server="http://http-ws.bbc.co.uk.edgesuite.net"
#                identifier="/generatecssram.esi?file=/worldservice/css/nb/410591221152760.ra"
#                href="http://http-ws.bbc.co.uk.edgesuite.net/generatecssram.esi?file=/worldservice/css/nb/410591221152760.ra"
#        />
#</media>
#
sub get_audio_stream_download_url {
		my $ua = shift;
		my $url_1 = shift;
		my $url_2;
		
		logger "\rGetting iplayer download URL         " if ! $opt{verbose};
		my $h = new HTTP::Headers(
			'User-Agent'	=> $user_agent{coremedia},
			'Accept'	=> '*/*',
			'Range'		=> 'bytes=0-',
		);
		my $req = HTTP::Request->new ('GET', $url_1, $h);
		# send request
		my $res = $ua->request($req);
		# Get resulting content 
		my $content = $res->content;
		# Flatten
		$content =~ s/\n/ /g;
		if ( ! $res->is_success ) {
			logger "ERROR: Failed to get audio url from iplayer site\n\n";
			return '';
		}
		# If we get a Redirection containing statuscode=404 then this prog is not yet ready
		if ( $content =~ /statuscode=404/ ) {
			logger "\rERROR: Programme is not yet ready for download\n";
			return '';
		}
		# extract ram URL
		$url_2 = $2 if $content =~ m{<media kind="(|audio)"\s*type="audio/real".*href="(.+?)"\s*};

		# If we cannot see 'encoding="real"...' then we don't have real audio transcoded format then skip
		if ( ! $url_2 ) {
			logger "\rERROR: Programme is not yet ready for download in RealAudio format\n";
			return '';
		}

		return $url_2;
}



# Given page content, extract the Versions and Pids and return in a hash: Versions => Pid
#<!--
#	iplayer.episode.setPidData("b0078vh4","b005rpmb");
#	iplayer.episode.setTitle("Razzledazzle: Dog");
#	iplayer.episode.setDownloadAvailability(1);
#	iplayer.episode.init();	
#		
#		iplayer.episode.buildVideoPlayer();
#		
#		
#//-->
sub get_version_pids {
	my @content = @_;
	# Extract pid versions 
	chomp( my $pid = (grep /iplayer\.episode\.setPidData/, @content)[0] );
	# Remove tags
	$pid =~ s/^.*\"([\w\d]+)\"\).*$/$1/g;
	# Get hash of pid => version
	my %version_pids;
	$version_pids{'Original'} = $pid;
	logger "INFO: Versions available: ".join(', ', %version_pids)."\n" if $opt{verbose};
	return %version_pids;
}



# Generate the download filename prefix given a pid and optional format such as '<longname> - <episode> <pid> <version>'
sub generate_download_filename_prefix {
	my $pid = shift;
	my $dir = shift;
	my $file = shift || "<longname> - <episode> <pid> <version>";
	# If we dont have longname defined just set it to name
	$prog{$pid}{longname} = $prog{$pid}{name} if ! $prog{$pid}{longname};

	# Create a filename
	# Tokenize and substitute $format
	for my $key ( keys %{ $prog{$pid} } ) {
		my $replace = $prog{$pid}{$key};
		$file =~ s|\<$key\>|$replace|gi;
	}
	$file =~ s|<pid>|$pid|gi;
	
	# Replace slashes with _ regardless
	$file =~ s/[\\\/]/_/g;
	# Sanitize by default
	$file =~ s/\s/_/g if ! $opt{whitespace};
	$file =~ s/[^\w_-]//gi if ! $opt{whitespace};

	# Don't create subdir if we are only testing downloads
	# Create a subdir for programme sorting option
	if ( $opt{subdir} && ! $opt{test} ) {
	        my $subdir = "$prog{$pid}{longname}";
                $subdir =~ s/[\\\/]/_/g;
                $subdir =~ s/\s/_/g if ! $opt{whitespace};
                $subdir =~ s/[^\w_-]//gi if ! $opt{whitespace};
                $file = "${subdir}/${file}";
                # Create dir if it does not exist
                mkdir("${dir}/${subdir}") if ! -d "${dir}/${subdir}";
        }

        return $file;
}



sub get_web_bugs {
	my $ua = shift;
	my @content = @_;
	my $h;
	my $req;
	my $res;
	
	# Load cookies and check if we have a BBC-UID cookie in there
	my $cookies = HTTP::Cookies->new;
	$cookies->load( $cookiejar );
	if ( $cookies->as_string =~ /BBC\-UID=/ ) {
		logger "INFO: Cookie already exists\n" if $opt{verbose};
		return 0;
	}
	
	# Parse this to get o.gif for stats web bug
	#var i = new Image(1,1); i.src = "http://stats.bbc.co.uk/o.gif?~RS~s~RS~iPlayer~RS~t~RS~Web_progi~RS~i~RS~b00cc05l~RS~p~RS~0~RS~a~RS~0~RS~u~RS~/iplayer/_proxy_/episode/b00cc05l~RS~r~RS~(none)~RS~q~RS~~RS~z~RS~17~RS~";
        chomp( my $url_1b = (grep /i\.src\s*=\s*\"http:\/\/stats\.bbc\.co\.uk\/o\.gif.*b0\w{5}.*\";/, @content)[0] );
        $url_1b =~ s/^.*i\.src\s*=\s*\"(http:\/\/stats\.bbc\.co\.uk\/o\.gif.*b0\w{5}.*)\";.*$/$1/g;
        logger "INFO: Web bug#1: $url_1b\n" if $opt{verbose};

        # Stage 1b - get o.gif web bug to whitelist cookie
        #my $url_1b = 'http://stats.bbc.co.uk/o.gif?~RS~s~RS~iplayer~RS~t~RS~Web_progi~RS~i~RS~b00c3rtd~RS~p~RS~0~RS~a~RS~0~RS~u~RS~/iplayer/page/item/b00c3rtd.shtml~RS~r~RS~(none)~RS~q~RS~q=graham+norton&amp;go=Find+Programmes&amp;scope=iplayersearch&amp;start=1&amp;version_pid=b00c3rrt~RS~z~RS~50~RS~ HTTP/1.1';
	logger "INFO: Getting iplayer 1st web bug              \r";
	#GET /o.gif?~RS~s~RS~iplayer~RS~t~RS~Web_progi~RS~i~RS~b00c3rtd~RS~p~RS~0~RS~a~RS~0~RS~u~RS~/iplayer/page/item/b00c3rtd.shtml~RS~r~RS~(none)~RS~q~RS~q=graham+norton&amp;go=Find+Programmes&amp;scope=iplayersearch&amp;start=1&amp;version_pid=b00c3rrt~RS~z~RS~50~RS~ HTTP/1.1
	#Accept: */*
	#Accept-Language: en
	#Accept-Encoding: gzip, deflate
	#Cookie: BBC-UID=54xxxxxxxxx71ad6e33cfdf040e01b44068765f2a0b061b4447fe92f6528b1ae0Mozilla%2f5%2e0%20%28iPod%3b%20U%3b%20CPU%20like%20Mac%20OS%20X%3b%20en%29
	#Referer: http://www.bbc.co.uk/iplayer/page/item/b00c3rtd.shtml?q=graham+norton&go=Find+Programmes&scope=iplayersearch&start=1&version_pid=b00c3rrt
	#User-Agent: Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3B48b Safari/419.3
	#Connection: keep-alive
	#Host: stats.bbc.co.uk
	$h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{safari},
		'Accept'	=> '*/*',
	);
	$req = HTTP::Request->new ('GET', $url_1b, $h);
	# send request
	$res = $ua->request($req);
	# Get resulting Location header (i.e. redirect URL)
	if ( ! $res->is_success ) {
		logger "ERROR: Failed to get o.gif web bug from iplayer site\n";
		# Better remove our cookie cos it probably isn't whitelisted
		$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 0, ignore_discard => 0 ) );
		unlink $cookiejar;
		return 2;
	}


	# Stage 1c - get o.gif framework web bug to whitelist cookie (5 digit random number appended)
	my $url_1c = $web_bug_2_url.(sprintf "%05.0f", 100000*rand(0));
	logger "INFO: Getting iplayer 2nd web bug             \r";
        #GET /iplayer/framework/img/o.gif?90927 HTTP/1.1
        #Accept: */*
        #Accept-Language: en
        #Accept-Encoding: gzip, deflate
        #Cookie: BBC-UID=e4xxxxxx731e0ec0d34a019ab030cb2de22aef9c407041d4343f4937d42343d40Mozilla%2f5%2e0%20%28iPod%3b%20U%3b%20CPU%20like%20Mac%20OS%20X%3b%20en%29%20AppleWebKit%2f420%2e1%20%28KHTML%2c%20like%20Gecko%29%20Version%2f3%2e0%20Mobile%2f3B48b%20Safari%2f419%2e3
        #Referer: http://www.bbc.co.uk/iplayer/page/item/b00c3rtd.shtml?q=graham+norton&go=Find+Programmes&scope=iplayersearch&start=1&version_pid=b00c3rrt
        #User-Agent: Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3B48b Safari/419.3
        #Connection: keep-alive
        #Host: www.bbc.co.uk
	$h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{safari},
		'Accept'	=> '*/*',
	);
	$req = HTTP::Request->new ('GET', $url_1c, $h);
	# send request
	$res = $ua->request($req);
	# Get resulting Location header (i.e. redirect URL)
	if ( ! $res->is_success ) {
		logger "ERROR: Failed to get 2nd o.gif web bug from iplayer site\n";
		# Better remove our cookie cos it probably isn't whitelisted
		$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 0, ignore_discard => 0 ) );
		unlink $cookiejar;
		return 2;
	}

	return 0;
}



# Usage: moov_length = relocate_moov_chunk_offsets(<binary string>)
sub relocate_moov_chunk_offsets {
	my $moovdata = $_[0];
	# Change all the chunk offsets in moov->stco atoms and add moov_length to them all
	# get moov atom length
	my $moov_length = bytestring_to_int( substr($moovdata, 0, 4) );
	# Use index() to seatch for a string within a string
	my $i = -1;
	while (($i = index($moovdata, 'stco', $i)) > -1) {

		# determine length of atom (4 bytes preceding stco)
		my $stco_len = bytestring_to_int( substr($moovdata, $i-4, 4) );
		logger "INFO: Found stco atom at moov atom offset: $i length $stco_len\n" if $opt{verbose};

		# loop through all chunk offsets in this atom and add offset (== moov atom length)
		for (my $j = $i+12; $j < $stco_len+$i-4; $j+=4) {
			my $chunk_offset = bytestring_to_int( substr($moovdata, $j, 4) );
			#logger "chunk_offset @ $i, $j = '".get_hex( substr($moovdata, $j, 4) )."',	$chunk_offset + $moov_length = ";
			$chunk_offset += $moov_length;
			# write back bytes into $moovdata
			substr($moovdata, $j+0, 1) = chr( ($chunk_offset >> 24) & 0xFF );
			substr($moovdata, $j+1, 1) = chr( ($chunk_offset >> 16) & 0xFF );
			substr($moovdata, $j+2, 1) = chr( ($chunk_offset >>  8) & 0xFF );
			substr($moovdata, $j+3, 1) = chr( ($chunk_offset >>  0) & 0xFF );
			#$chunk_offset = bytestring_to_int( substr($moovdata, $j, 4) );
			#logger "$chunk_offset\n";
		}

		# skip over this whole atom now it is processed
		$i += $stco_len;
	}
	# Write $moovdata back to calling string
	$_[0] = $moovdata;
	return $moov_length;
}



# Usage download_block($file, $url_2, $ua, $start, $end, $file_len, $fh);
#  ensure filehandle $fh is open in append mode
# or, $content = download_block(undef, $url_2, $ua, $start, $end, $file_len);
# Called in 4 ways:
# 1) write to real file			=> download_block($file, $url_2, $ua, $start, $end, $file_len, $fh);
# 2) write to real file + STDOUT	=> download_block($file, $url_2, $ua, $start, $end, $file_len, $fh); + $opt{stdout}==true
# 3) write to STDOUT only		=> download_block($file, $url_2, $ua, $start, $end, $file_len, $fh); + $opt{stdout}==true + $opt{nowrite}==false
# 4) write to memory (and return data)  => download_block(undef, $url_2, $ua, $start, $end, $file_len, undef);
# 4) write to memory (and return data)  => download_block(undef, $url_2, $ua, $start, $end);
sub download_block {

	my ($file, $url, $ua, $start, $end, $file_len, $fh) = @_;
	my $orig_length;
	my $buffer;
	my $lastpercent = 0;
	$now = time();

	# If this is an 'append to file' mode call
	if ( defined $file && $fh && (!$opt{nowrite}) ) {
		# Stage 3b: Download File
		$orig_length = tell $fh;
		logger "INFO: Appending to $file\n" if $opt{verbose};
	}

	# Setup request headers
	my $h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{coremedia},
		'Accept'	=> '*/*',
		'Range'        => "bytes=${start}-${end}",
	);

	my $req = HTTP::Request->new ('GET', $url, $h);

	# Set time to use for download rate calculation
	# Define callback sub that gets called during download request
	# This sub actually writes to the open output file and reports on progress
	my $callback = sub {
		my ($data, $res, undef) = @_;
		# Don't write the output to the file if there is no content-length header
		return 0 if ( ! $res->header("Content-Length") );
		# If we don't know file length in advanced then set to size reported reported from server upon download
		$file_len = $res->header("Content-Length") + $start if ! defined $file_len;
		# Write output
		print $fh $data if ! $opt{nowrite};
		print STDOUT $data if $opt{stdout};
		# return if streaming to stdout - no need for progress
		return if $opt{stdout} && $opt{nowrite};
		return if $opt{quiet};
		# current file size
		my $size = tell $fh;
		# Download percent
		my $percent = 100.0 * $size / $file_len;
		# Don't update display if we haven't dowloaded at least another 0.1%
		return if ($percent - $lastpercent) < 0.1;
		$lastpercent = $percent;
		# download rates in bytes per second and time remaining
		my $rate_bps;
		my $rate;
		my $time;
		my $timecalled = time();
		if ($timecalled - $now < 1) {
			$rate = '-----kbps';
			$time = '--:--:--';
		} else {
			$rate_bps = ($size - $orig_length) / ($timecalled - $now);
			$rate = sprintf("%5.0fkbps", (8.0 / 1024.0) * $rate_bps);
			$time = sprintf("%02d:%02d:%02d", ( gmtime( ($file_len - $size) / $rate_bps ) )[2,1,0] );
		}
		printf STDERR "%8.2fMB / %.2fMB %s %5.1f%%, %s remaining         \r", 
			$size / 1024.0 / 1024.0, 
			$file_len / 1024.0 / 1024.0,
			$rate,
			$percent,
			$time,
		;
	};

	my $callback_memory = sub {
		my ($data, $res, undef) = @_;
		# append output to buffer
		$buffer .= $data;
		return if $opt{quiet};
		# current buffer size
		my $size = length($buffer);
		# download rates in bytes per second
		my $timecalled = time();
		my $rate_bps;
		my $rate;
		my $time;
		my $percent;
		# If we can get Content_length then display full progress
		if ($res->header("Content-Length")) {
			$file_len = $res->header("Content-Length") if ! defined $file_len;
			# Download percent
			$percent = 100.0 * $size / $file_len;
			return if ($percent - $lastpercent) < 0.1;
			$lastpercent = $percent;
			# Block length
			$file_len = $res->header("Content-Length");
			if ($timecalled - $now < 0.1) {
				$rate = '-----kbps';
				$time = '--:--:--';
			} else {
				$rate_bps = $size / ($timecalled - $now);
				$rate = sprintf("%5.0fkbps", (8.0 / 1024.0) * $rate_bps );
				$time = sprintf("%02d:%02d:%02d", ( gmtime( ($file_len - $size) / $rate_bps ) )[2,1,0] );
			}
			# time remaining
			printf STDERR "%8.2fMB / %.2fMB %s %5.1f%%, %s remaining         \r", 
				$size / 1024.0 / 1024.0,
				$file_len / 1024.0 / 1024.0,
				$rate,
				$percent,
				$time,
			;
		# Just used simple for if we cannot determine content length
		} else {
			if ($timecalled - $now < 0.1) {
				$rate = '-----kbps';
			} else {
				$rate = sprintf("%5.0fkbps", (8.0 / 1024.0) * $size / ($timecalled - $now) );
			}
			printf STDERR "%8.2fMB %s         \r", $size / 1024.0 / 1024.0, $rate;
		}
	};

	# send request
	logger "\nINFO: Downloading range ${start}-${end}\n" if $opt{verbose};
	logger "\r                              \r";
	my $res;

	# If $fh undefined then get block to memory (fh always defined for stdout or file d/load)
	if (defined $fh) {
		logger "DEBUG: writing stream to stdout, Range: $start - $end of $url\n" if $opt{verbose} && $opt{stdout};
		logger "DEBUG: writing stream to $file, Range: $start - $end of $url\n" if $opt{verbose} && !$opt{nowrite};
		$res = $ua->request($req, $callback);
		if (  (! $res->is_success) || (! $res->header("Content-Length")) ) {
			logger "ERROR: Failed to Download block\n\n";
			return 5;
		}
                logger "INFO: Content-Length = ".$res->header("Content-Length")."                               \n" if $opt{verbose};
		return 0;
		   
	# Memory Block
	} else {
		logger "DEBUG: writing stream to memory, Range: $start - $end of $url\n" if $opt{debug};
		$res = $ua->request($req, $callback_memory);
		if ( (! $res->is_success) ) {
			logger "ERROR: Failed to Download block\n\n";
			return '';
		} else {
			return $buffer;
		}
	}
}



# Converts a string of chars to it's HEX representation
sub get_hex {
        my $buf = shift;
        my $ret;
        for (my $i=0; $i<length($buf); $i++) {
                $ret .= " ".sprintf("%02lx", ord substr($buf, $i, 1) );
        }
	logger "DEBUG: HEX string value = $ret\n" if $opt{verbose};
        return $ret;
}



# Converts a string of chars to it's MSB decimal value
sub bytestring_to_int {
	# Reverse to LSB order
        my $buf = reverse shift;
        my $dec;
        for (my $i=0; $i<length($buf); $i++) {
		# Multiply byte value by 256^$i then accumulate
                $dec += (ord substr($buf, $i, 1)) * 256 ** $i;
        }
        #logger "DEBUG: Decimal value = $dec\n" if $opt{verbose};
        return $dec;
}



# version of unix tee
# Usage tee ($infile, $outfile)
# If $outfile is undef then just cat file to STDOUT
sub tee {
	my ( $infile, $outfile ) = @_;
	# Open $outfile for writing, $infile for reading
	if ( $outfile) {
		if ( ! open( OUT, "> $outfile" ) ) {
			logger "ERROR: Could not open $outfile for writing\n";
			return 1;
		} else {
			logger "INFO: Opened $outfile for writing\n" if $opt{verbose};
		}
	}
	if ( ! open( IN, "< $infile" ) ) {
		logger "ERROR: Could not open $infile for reading\n";
		return 2;
	} else {
		logger "INFO: Opened $infile for reading\n" if $opt{verbose};
	}
	# Read and redirect IN
	while ( <IN> ) {
		print $_;
		print OUT $_ if $outfile;
	}
	# Close output file
	close OUT if $outfile;
	close IN;
	return 0;
}



# Usage: $fh = open_file_append($filename);
sub open_file_append {
	local *FH;
	my $file = shift;
	# Just in case we actually write to the file - make this /dev/null
	$file = '/dev/null' if $opt{nowrite};
	if ($file) {
		if ( ! open(FH, ">> $file") ) {
			logger "ERROR: Cannot write or append to $file\n\n";
			exit 1;
		}
	}
	# Fix for binary - needed for Windows
	binmode FH;
	return *FH;
}



# Updates and overwrites this script - makes backup as <this file>.old
sub update_script {
	# Get version URL
	my $ua = LWP::UserAgent->new;
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->agent( $user_agent{update} );
	$ua->conn_cache(LWP::ConnCache->new());
	logger "INFO: Checking for latest version from linuxcentre.net\n";
	my $res = $ua->request( HTTP::Request->new( GET => $version_url ) );
	chomp( my $latest_ver = $res->content );
	if ( $res->is_success ) {
		# Compare version numbers
		if ( $latest_ver > $version ) {
			logger "INFO: New version $latest_ver available, downloading\n";
			my $res = $ua->request( HTTP::Request->new( GET => $update_url ) );		
			my $req = HTTP::Request->new ('GET', $update_url);
			# Save content into a $script_file
			my $script_file = $0;
			$ua->request($req, $script_file.'.tmp');
			# If the download was successful then copy over this script and make executable after making a backup of this script
			if ( $res->is_success ) {
				if ( copy($script_file, $script_file.'.old') ) {
					move($script_file.'.tmp', $script_file);
					chmod 0755, $script_file;
					logger "INFO: Copied new version $latest_ver into place (previous version is now called '${script_file}.old')\n";
				}
			}
		} else {
			logger "INFO: No update is necessary (latest version = $latest_ver)\n";
		}
	} else {
		logger "ERROR: Failed to connect to update site\n";
		exit 2;
	}
	exit 0;
}



# Creates the Freevo FXD or MythTV Streams meta data (and pre-downloads graphics - todo)
sub create_xml {
	my $xmlfile = shift;
	if ( ! open(XML, "> $xmlfile") ) {
		logger "ERROR: Couldn't open xml file $xmlfile for writing\n";
		return 1;
	}
	print XML '<?xml version="1.0" ?>';
	print XML '<freevo>' if $opt{fxd};
	print XML "\n<MediaStreams>\n" if $opt{mythtv};

	if ( $opt{xmlnames} ) {
		# containers sorted by prog names
		print XML "\t<container title=\"iplayer by Programme Name\">\n" if $opt{fxd};
		my %program_index;
		my %program_count;
		# create hash of programme_name -> index
	        for (@_) {
	        	$program_index{$prog{$index_pid{$_}}{name}} = $_;
			$program_count{$prog{$index_pid{$_}}{name}}++;
		}
		for my $name ( sort keys %program_index ) {
			my @count = grep /^$name$/, keys %program_index;
			print XML "\t<container title=\"".encode_entities( $name )." ($program_count{$name})\">\n" if $opt{fxd};
			print XML "\t<Streams>\n" if $opt{mythtv};
			for (@_) {
				my $pid = $index_pid{$_};
				# loop through and find matches for each progname
				if ( $prog{$index_pid{$_}}{name} =~ /^$name$/ ) {
					my $episode = encode_entities( $prog{$pid}{episode} );
					my $desc = encode_entities( $prog{$pid}{desc} );
					my $title = "${episode} ($prog{$pid}{available})";
					print XML "<movie title=\"${title}\">
						<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
						<info><description>${desc}</description></info>
					</movie>\n" if $opt{fxd};
					print XML "<Stream>
						<Name>\"${title}\"</Name>
						<url>${pid}.mov</url>
						<Subtitle></Subtitle>
						<Synopsis>${desc}</Synopsis>
					</Stream>\n" if $opt{mythtv};
				}
			}			
			print XML "\t</container>\n" if $opt{fxd};
			print XML "\t</Streams>\n" if $opt{mythtv};
		}
		print XML "\t</container>\n" if $opt{fxd};
	}


	if ( $opt{xmlchannels} ) {
		# containers for prog names sorted by channel
		print XML "\t<container title=\"iplayer by Channel\">\n" if $opt{fxd};
		my %program_index;
		my %program_count;
		my %channels;
		# create hash of unique channel names and hash of programme_name -> index
	        for (@_) {
	        	$program_index{$prog{$index_pid{$_}}{name}} = $_;
			$program_count{$prog{$index_pid{$_}}{name}}++;
			$channels{$prog{$index_pid{$_}}{channel}} .= '|'.$prog{$index_pid{$_}}{name}.'|';
		}
		for my $channel ( sort keys %channels ) {
			print XML "\t<container title=\"".encode_entities( $channel )."\">\n" if $opt{fxd};
			print XML "\t<Feed>
				\t<Name>".encode_entities( $channel )."</Name>
				\t<Provider>BBC</Provider>\n
				\t<Streams>\n" if $opt{mythtv};
			for my $name ( sort keys %program_index ) {
				# Do we have any of this prog $name on this $channel?
				if ( $channels{$channel} =~ /\|$name\|/ ) {
					my @count = grep /^$name$/, keys %program_index;
					print XML "\t<container title=\"".encode_entities( $name )." ($program_count{$name})\">\n" if $opt{fxd};
					print XML "\t\t<Stream>\n" if $opt{mythtv};
					for (@_) {
						# loop through and find matches for each progname for this channel
						my $pid = $index_pid{$_};
						if ( $prog{$pid}{channel} =~ /^$channel$/ && $prog{$pid}{name} =~ /^$name$/ ) {
							my $episode = encode_entities( $prog{$pid}{episode} );
							my $desc = encode_entities( $prog{$pid}{desc} );
							my $title = "${episode} ($prog{$pid}{available})";
							print XML "<movie title=\"${title}\">
								<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
								<info><description>${desc}</description></info>
							</movie>\n" if $opt{fxd};
							print XML "\t\t<Name>$name</Name>\n\t\t<Url>${pid}.mov</Url>\n\t\t<Subtitle>${episode}</Subtitle>\n\t\t<Synopsis>${desc}</Synopsis>\n" if $opt{mythtv};
						}
					}
					print XML "\t</container>\n" if $opt{fxd};
					print XML "\t</Stream>\n" if $opt{mythtv};
				}
			}
			print XML "\t</container>\n" if $opt{fxd};
			print XML "\t</Streams>\n\t</Feed>\n" if $opt{mythtv};
		}
		print XML "\t</container>\n" if $opt{fxd};
	}


	if ( $opt{xmlalpha} ) {
		my %table = (
			'A-C' => '[abc]',
			'D-F' => '[def]',
			'G-I' => '[ghi]',
			'J-L' => '[jkl]',
			'M-N' => '[mn]',
			'O-P' => '[op]',
			'Q-R' => '[qt]',
			'S-T' => '[st]',
			'U-V' => '[uv]',
			'W-Z' => '[wxyz]',
			'0-9' => '[\d]',
		);
		print XML "\t<container title=\"iplayer A-Z\">\n";
		for my $folder (sort keys %table) {
			print XML "\t<container title=\"iplayer $folder\">\n";
			for (@_) {
				my $pid = $index_pid{$_};
				my $name = encode_entities( $prog{$pid}{name} );
				my $episode = encode_entities( $prog{$pid}{episode} );
				my $desc = encode_entities( $prog{$pid}{desc} );
				my $title = "${name} - ${episode} ($prog{$pid}{available})";
				my $regex = $table{$folder};
				if ( $name =~ /^$regex/i ) {
					print XML "<movie title=\"${title}\">
						<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
						<info><description>${desc}</description></info>
					</movie>\n" if $opt{fxd};
					print XML "<Stream title=\"${title}\">
						<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
						<info><description>${desc}</description></info>
					</Stream>\n" if $opt{mythtv};
				}
			}
			print XML "\t</container>\n";
		}
		print XML "\t</container>\n";
	}

	print XML '</freevo>' if $opt{fxd};
	print XML '</MediaStreams>' if $opt{mythtv};
	close XML;
}



sub create_html {
	# Create local web page
	if ( open(HTML, "> $opt{html}") ) {
		print HTML '<html><head></head><body><table border=1>';
		for (@_) {
			my $pid = $index_pid{$_};
			my $name = encode_entities( $prog{$pid}{name} );
			my $episode = encode_entities( $prog{$pid}{episode} );
			my $desc = encode_entities( $prog{$pid}{desc} );
			my $channel = encode_entities( $prog{$pid}{channel} );
			print HTML "<tr>
					<td rowspan=2 width=150><a href=\"${prog_page_prefix}/${pid}.html\"><img height=84 width=150 src=\"$prog{$pid}{thumbnail}\"></a></td>
					<td>$_</td>
					<td><a href=\"${prog_page_prefix}/${pid}.html\">${name}</a></td>
					<td>${episode}</td>
					<td>${channel}</td>
				</tr>
				<tr>
					<td colspan=5>${desc}</td>
				</tr>
			\n";
		}
		print HTML '</table></body>';
		close (HTML);
	} else {
		logger "Couldn't open html file $opt{html} for writing\n";
	}
}



# Save options to file
sub save_options_file {
	my $optfile = shift;
	unlink $optfile;
	logger "DEBUG: Saving options to $optfile:\n" if $opt{debug};
	open (OPT, "> $optfile") || die ("ERROR: Cannot save options to $optfile\n");
	# Save all opts except for these
	for (grep !/(help|test|debug|get)/, keys %opt) {
		print OPT "$_ $opt{$_}\n"  if defined $opt{$_};
		logger "DEBUG: Setting option $_ = $opt{$_}\n" if $opt{debug} && defined $opt{$_};
	}
	close OPT;
	logger "INFO: Options saved as defult in $optfile\n";
	exit 0;
}



# Load default options from file
sub read_options_file {
	my $optfile = shift;
	return 0 if ! -f $optfile;
	logger "DEBUG: Parsing options from $optfile:\n" if $opt{debug};
	open (OPT, "< $optfile") || die ("ERROR: Cannot read options file $optfile\n");
	while(<OPT>) {
		/^\s*([\w\-_]+)\s+(.*)\s*$/;
		chomp( $opt{$1} = $2 );
		logger "DEBUG: Setting option $1 = $2\n" if $opt{debug};
	}
	close OPT;
}



# Get time ago made available (x days y hours ago) from '2008-06-22T05:01:49Z' and current time
sub get_available_time_string {
	my $datestring = shift;
	# extract $year $mon $mday $hour $min $sec
	$datestring =~ m{(\d\d\d\d)\-(\d\d)\-(\d\d)T(\d\d):(\d\d):(\d\d)Z};
	my ($year, $mon, $mday, $hour, $min, $sec) = ($1, $2, $3, $4, $5, $6);
	# Calculate the seconds difference between epoch_now and epoch_datestring and convert back into array_time
	my @time = gmtime( time() - timelocal($sec, $min, $hour, $mday, ($mon-1), ($year-1900), undef, undef, 0) );
	return "$time[7] days $time[2] hours ago";
}



# get full episode metadata given pid and ua. Uses two different urls to get data
sub get_pid_metadata {
	my $ua = shift;
	my $pid = shift;
	my $metadata;
	my $entry;
	my $entry2;

	# This URL works for all prog types:
	# http://www.bbc.co.uk/iplayer/playlist/${pid}

	# This URL only works for TV progs:
	# http://www.bbc.co.uk/iplayer/metafiles/episode/${pid}.xml

	# This URL works for tv/radio prog types:
	# http://www.bbc.co.uk/iplayer/widget/episodedetail/episode/${pid}/template/mobile/service_type/tv/

	# Only supply this if a TV prog
	if ( $prog{$pid}{type} =~ /tv/i ) {
		logger "DEBUG: Getting episode data for ${pid}\n" if $opt{verbose};
		$entry = request_url_retry($ua, "${metadata_xml_prefix}/${pid}.xml", 3, '', '');
		decode_entities($entry);
		# Flatten
		$entry =~ s|\n| |g;
		# Remove any related programme data
		$entry =~ s|<relatedConcepts>.*$||gi;
	}

	if ( $prog{$pid}{type} =~ /(tv|radio)/i ) {
		$entry2 = request_url_retry($ua, "${metadata_mobile_prefix}/${pid}/template/mobile/service_type/tv/", 3, '', '');
		decode_entities($entry2);
		# Flatten
		$entry2 =~ s|\n| |g;
		# Remove any related programme data
		$entry2 =~ s|<relatedConcepts>.*$||gi;
	}


	# entry Format:
	# <?xml version="1.0" encoding="UTF-8"?> <iplayerMedia version="0.2">    <concept>          <pid>b00c7ytx</pid>
	#     <url>http://www.bbc.co.uk/iplayer/page/item/b00c7ytx.shtml</url>     <title>Doctor Who: Series 4</title>
	#     <subtitle>Turn Left</subtitle>     <thumbnail>    
	#   <url>http://www.bbc.co.uk/iplayer/images/episode/b00c7ytx_512_288.jpg</url>   
	#    <width>512</width>       <height>288</height>       <mediaType>image/jpeg</mediaType>     </thumbnail>  
	#    <shortSynopsis>Can Donna and Rose stop the approaching Darkness?</shortSynopsis>  
	#   <mediumSynopsis>As Donna's world collapses, she finds help from a mysterious blonde woman - but can Donna and Rose stop the approaching Darkness?</mediumSynopsis>  
	#   <longSynopsis></longSynopsis>     <masterbrand id="bbc_one">  
	#     <thumbnail>         <url>http://www.bbc.co.uk/iplayer/framework/img/ch/bbc_one.gif</url>         <width>54</width> 
	#<!-- Note:these value are currently hard coded as they're not in the content package -->         <height>40</height>     
	#     <mediaType>image/gif</mediaType>       </thumbnail>   
	#    <ident>          <server>cp44293.edgefcs.net</server>          <identifier>public/bbc_one</identifier>    
	#     <width>512</width>         <height>288</height>         <mediaType>video/x-flv</mediaType>       </ident>     </masterbrand>      
	#   <versions><!-- there will only be one version for launch. This will be the first available version -->  
	#      <version>           <name>AudioDescribed,Original</name>      
	#     <pid>b00c7yq9</pid>           <guidance>             <text></text>           </guidance>     
	#      <duration>00:45:00</duration>            <available>true</available>         </version>              </versions>
	
	# entry2 Format:
	# 	<h1>Doctor Who: Series 4</h1>
	#<div id="p-panel-episode">
	#        <div id="episode-image">
	#                <a href="#" id="version" pid="b00c7yq9"><img id="play-version" pid="b00c7yq9" src="img/click_to_play.png" /></a>
	#                <img src="/iplayer/images/episode/b00c7ytx_314_176.jpg" />
	#                <div id="player-container"></div>
	#
	#                <div id="info-message"></div>
	#        </div>
	#        <h2>Turn Left <span>-  45 mins</span></h2>
	#        <p><img class="episode-masterbrand" src="img/bbc_one.png"> As Donna's world collapses, she finds help from a mysterious blonde woman - but can Donna and Rose stop the approaching Darkness?</p>
	#        <p>Available till:  8:54pm Friday 11th July</p>

	# Format: http://www.bbc.co.uk/iplayer/playlist/b00c8ssg
	#<?xml version="1.0" encoding="UTF-8"?>
	#
	#<playlist xmlns="http://bbc.co.uk/2008/emp/playlist" revision="1">
	#  <id>tag:bbc.co.uk,2008:iplayer:b00c8ssg:playlist</id>
	#  <link rel="self" href="http://www.bbc.co.uk/iplayer/playlist/b00c8ssg"/>
	#  <link rel="alternate" href="http://www.bbc.co.uk/iplayer/episode/b00c8ssg"/>
	#  <link rel="holding" href="http://www.bbc.co.uk/iplayer/images/episode/b00c8ssg_640_360.jpg" height="360" width="640" type="image/jpeg" />
	#  <title>Eddie Halliwell: 03/07/2008</title>
	#  <summary>With two hours of the best new trance and techno.</summary>
	#  <updated>2008-06-26T01:01:37Z</updated>
	#  <item kind="radioProgramme" duration="7200" identifier="b00c8smr" group="b00c8ssg" publisher="pips">
	#    <title>Eddie Halliwell: 03/07/2008</title>
	#    <broadcast>2008-07-03T23:00:00</broadcast>
	#    <service id="bbc_radio_one" href="http://www.bbc.co.uk/iplayer/bbc_radio_one">BBC Radio 1</service>
	#    <masterbrand id="bbc_radio_one" href="http://www.bbc.co.uk/iplayer/bbc_radio_one">BBC Radio 1</masterbrand>
	#    <passionSite href="http://www.bbc.co.uk/programmes/b006wq9w/microsite">Eddie Halliwell</passionSite>
	#    <mediator identifier="b00c8smr" name="pips"/>
	#  </item>
	#</playlist>

	my ($duration, $available, $channel, $expiry, $longdesc, $versions, $guidance);

	$expiry = $1 if $entry2 =~ m{<p>Available till:\s*(.*?)\s*</p>};
	$duration = $1 if $entry =~ m{<duration>\s*(.*?)\s*</duration>};
	$channel = $1 if $entry =~ m{<masterbrand id="\s*(.*?)\s*">};
	$available = $1 if $entry =~ m{<available>\s*(.*?)\s*</available>};
	$longdesc = $1 if $entry =~ m{<longSynopsis>\s*(.*?)\s*</longSynopsis>};
	if (! $longdesc) {
		$longdesc = $1 if $entry =~ m{<mediumSynopsis>\s*(.*?)\s*</mediumSynopsis>};
	}
	if (! $longdesc) {
		$longdesc = $1 if $entry =~ m{<shortSynopsis>\s*(.*?)\s*</shortSynopsis>};
	}
	$versions = $1 if $entry =~ m{<name>\s*(.*?)\s*</name>};
	$guidance = $1 if $entry =~ m{<guidance>\s*<text>\s*(.*?)\s*</text>};

	# Fill in from cache if not got from metadata
	$metadata .= "\nPid:\t\t$pid\n";
	$metadata .= "Index:\t\t$prog{$pid}{index}\n";
	$metadata .= "Duration:\t".	($duration || $prog{$pid}{duration})	."\n";
	$metadata .= "Channel:\t".	($channel || $prog{$pid}{channel})	."\n";
	$metadata .= "Available:\t".	($available || $prog{$pid}{available})	."\n";
	$metadata .= "Expires:\t".	($expiry || $prog{$pid}{expiry})	."\n";
	$metadata .= "Versions:\t".	($versions || $prog{$pid}{versions})	."\n";
	$metadata .= "Guidance:\t".	($guidance || $prog{$pid}{guidance})	."\n";
	$metadata .= "Categories:\t".	$prog{$pid}{categories}			."\n";
	$metadata .= "Description:\t".	($longdesc || $prog{$pid}{desc})	."\n";

	return $metadata;
}



# Gets the contents of a URL and retries if it fails, returns '' if no page could be retrieved
# Usage <content> = request_url_retry(<ua>, <url>, <retries>, <succeed message>, [<fail message>]);
sub request_url_retry {
	my ($ua, $url, $retries, $succeedmsg, $failmsg) = @_; 
	my $res;

	my $i;
	logger "INFO: Getting page $url\n" if $opt{verbose};
	for ($i = 0; $i < $retries; $i++) {
		$res = $ua->request( HTTP::Request->new( GET => $url ) );
		if ( ! $res->is_success ) {
			logger $failmsg;
		} else {
			logger $succeedmsg;
			last;
		}
	}
	# Return empty string if we failed
	return '' if $i == $retries;
	# otherwise return content
	return $res->content;
}



# Checks if a particular program exists (or program.exe) in the $ENV{PATH} or if it has a path already check for existence of file
sub exists_in_path {
	my $file = shift;
	# If this has a path specified, does file exist
	return 1 if $file =~ /[\/\\]/ && (-f $file || -f "${file}.exe");
	# Search PATH
	for (@PATH) {
		return 1 if -f "${_}/${file}" || -f "${_}/${file}.exe";
	}
	return 0;
}



# Run a user specified command
# e.g. --command 'echo "<pid> <longname> downloaded"'
# run_user_command($pid, 'echo "<pid> <longname> downloaded"');
sub run_user_command {
	my $pid = shift;
	my $command = shift;

	# Tokenize and substitute $format
	for my $key ( keys %{ $prog{$pid} } ) {
		$command =~ s|\<$key\>|$prog{$pid}{$key}|gi;
	}
	$command =~ s|<pid>|$pid|gi;

	# Escape chars in command for shell use
	esc_chars(\$command);

	# run command
	logger "INFO: Running command '$command'\n" if $opt{verbose};
	my $exit_value = system $command;
	
	# make exit code sane
	$exit_value = $exit_value >> 8;
	logger "ERROR: Command Exit Code: $exit_value\n" if $exit_value;
	logger "INFO: Command succeeded\n" if $opt{verbose} && ! $exit_value;
        return 0;
}



# Adds pid to history file (with a timestamp) so that it is not redownloaded after deletion
sub add_to_download_history {
	my $pid = shift;
	# Only add if a pid is specified
	return 0 if ! $pid;
	# Don't add to history if stdout streaming is used
	return 0 if ( $opt{stdout} && $opt{nowrite} ) || $opt{streaminfo};

	# Add to history
	if ( ! open(HIST, ">> $historyfile") ) {
		logger "WARNING: Cannot write or append to $historyfile\n\n";
		return 1;
	}
	print HIST "$pid|$prog{$pid}{name}|$prog{$pid}{episode}|$prog{$pid}{type}|".time()."\n";
	close HIST;
	return 0;
}



# Checks history for previous download of this pid
sub check_download_history {
	my $pid = shift;

	# Return if force-download option specified or stdout streaming only
	return 0 if $opt{forcedownload} || $opt{stdout} || $opt{nowrite};
	
	if ( ! open(HIST, "< $historyfile") ) {
		logger "WARNING: Cannot read $historyfile\n\n";
		return 0;
	}

	if ( $pid && grep /^$pid/, <HIST>) {
		logger "INFO: $pid Already in download history ($historyfile)\n";
		close HIST;
		return 1;

	} else {
		logger "INFO: PID not in download history\n" if $opt{verbose};
		close HIST;
		return 0;
	}
}



# Add id3 tag to MP3 files if required
sub tag_file {
	my $pid = shift;
	if ( $prog{$pid}{ext} eq 'mp3' ) {
		# Create ID3 tagging options for external tagger program (escape " for shell)
		my ( $id3_name, $id3_episode, $id3_desc, $id3_channel ) = ( $prog{$pid}{name}, $prog{$pid}{episode}, $prog{$pid}{desc}, $prog{$pid}{channel} );
		$id3_name =~ s|"|\"|g for ($id3_name, $id3_episode, $id3_desc, $id3_channel);
		# Only tag if the required tool exists
		if ( exists_in_path($id3v2) ) {
			logger "INFO: id3 tagging MP3 file\n";
			my $cmd = "$id3v2 --artist \"$id3_channel\" --album \"$id3_name\" --song \"$id3_episode\" --comment \"Description\":\"$id3_desc\" --year ".( (localtime())[5] + 1900 )." $prog{$pid}{filename} 1>&2";
			logger "DEGUG: Running $cmd\n" if $opt{debug};
			if ( system($cmd) ) {
				logger "WARNING: Failed to tag MP3 file\n";
				return 2;
			}
		} else {
			logger "WARNING: Cannot tag MP3 file\n" if $opt{verbose};
		}
	}
}



# Show channels for specified type if required
sub list_unique_element_counts {
	my $element_name = shift;
	my %elements;
	logger "INFO: $opt{type} $element_name List:\n" if $opt{verbose};
	for my $pid (keys %prog) {
		for my $element ( split /,/, $prog{$pid}{$element_name} ) {
			$elements{ $element }++;
		}
	}
	# display element + prog count
	logger "$_ ($elements{$_})\n" for sort keys %elements;
	return 0;
}



# Escape chars in string for shell use
sub esc_chars {
	# will change, for example, a!!a to a\!\!a
	s/([;<>\*\|&\$!#\(\)\[\]\{\}:'"])/\\$1/g;
	return $_;
}



# Signal handler to clean up after a ctrl-c or kill
sub cleanup {
	logger "Cleaning up\n" if $opt{verbose};
	unlink $namedpipe;
	exit 1;
}
